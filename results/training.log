2026-02-09 20:30:04,946 - __main__ - INFO - Starting hierarchical demand reconciliation training
2026-02-09 20:30:04,946 - __main__ - INFO - Arguments: Namespace(data_path='data', config='hierarchical-demand-reconciliation-with-temporal-anomaly-feedback/configs/default.yaml', synthetic_data=False, no_download=False, epochs=100, batch_size=64, learning_rate=0.001, weight_decay=0.0001, sequence_length=28, prediction_length=28, hidden_size=256, num_layers=4, num_heads=8, dropout=0.1, output_dir='results', checkpoint_dir='checkpoints', resume_from=None, device='auto', num_workers=4, seed=42, log_level='INFO')
2026-02-09 20:30:04,946 - __main__ - INFO - Configuration file not found, using default configuration
2026-02-09 20:30:05,027 - __main__ - INFO - Using device: cuda
2026-02-09 20:30:05,027 - __main__ - INFO - Using synthetic data
2026-02-09 20:30:05,027 - __main__ - INFO - Generating synthetic data: 100 items, 365 days
2026-02-09 20:30:05,165 - __main__ - INFO - Generated synthetic data with 36500 records
2026-02-09 20:30:05,166 - __main__ - INFO - Preparing data with simple preprocessing...
2026-02-09 20:30:05,174 - __main__ - INFO - Data split - Train: 25500, Val: 7300, Test: 3700
2026-02-09 20:30:05,708 - __main__ - INFO - Model has 3197596 parameters
2026-02-09 20:30:06,057 - __main__ - INFO - Starting training for 100 epochs...
2026-02-09 20:30:06,330 - __main__ - INFO - Epoch 1, Batch 0, Loss: 126.0124
2026-02-09 20:30:06,553 - __main__ - INFO - Epoch 1, Batch 50, Loss: 13.1194
2026-02-09 20:30:06,761 - __main__ - INFO - Epoch 1, Batch 100, Loss: 13.7868
2026-02-09 20:30:06,979 - __main__ - INFO - Epoch 1, Batch 150, Loss: 15.5224
2026-02-09 20:30:07,173 - __main__ - INFO - Epoch 1, Batch 200, Loss: 14.6401
2026-02-09 20:30:07,365 - __main__ - INFO - Epoch 1, Batch 250, Loss: 10.9394
2026-02-09 20:30:07,576 - __main__ - INFO - Epoch 1, Batch 300, Loss: 15.3118
2026-02-09 20:30:07,942 - __main__ - INFO - Epoch 1: Train Loss: 18.0524, Val Loss: 17.1897
2026-02-09 20:30:07,942 - __main__ - INFO - New best validation loss: 17.1897
2026-02-09 20:30:08,062 - __main__ - INFO - Epoch 2, Batch 0, Loss: 14.9004
2026-02-09 20:30:08,266 - __main__ - INFO - Epoch 2, Batch 50, Loss: 13.7497
2026-02-09 20:30:08,470 - __main__ - INFO - Epoch 2, Batch 100, Loss: 13.8136
2026-02-09 20:30:08,680 - __main__ - INFO - Epoch 2, Batch 150, Loss: 11.2460
2026-02-09 20:30:08,876 - __main__ - INFO - Epoch 2, Batch 200, Loss: 12.1957
2026-02-09 20:30:09,078 - __main__ - INFO - Epoch 2, Batch 250, Loss: 12.9424
2026-02-09 20:30:09,281 - __main__ - INFO - Epoch 2, Batch 300, Loss: 14.7210
2026-02-09 20:30:09,672 - __main__ - INFO - Epoch 2: Train Loss: 13.2066, Val Loss: 15.3086
2026-02-09 20:30:09,672 - __main__ - INFO - New best validation loss: 15.3086
2026-02-09 20:30:09,800 - __main__ - INFO - Epoch 3, Batch 0, Loss: 13.6198
2026-02-09 20:30:10,008 - __main__ - INFO - Epoch 3, Batch 50, Loss: 13.4812
2026-02-09 20:30:10,202 - __main__ - INFO - Epoch 3, Batch 100, Loss: 13.9574
2026-02-09 20:30:10,409 - __main__ - INFO - Epoch 3, Batch 150, Loss: 13.3469
2026-02-09 20:30:10,630 - __main__ - INFO - Epoch 3, Batch 200, Loss: 11.8631
2026-02-09 20:30:10,828 - __main__ - INFO - Epoch 3, Batch 250, Loss: 14.1771
2026-02-09 20:30:11,034 - __main__ - INFO - Epoch 3, Batch 300, Loss: 12.6474
2026-02-09 20:30:11,368 - __main__ - INFO - Epoch 3: Train Loss: 13.1349, Val Loss: 15.5191
2026-02-09 20:30:11,492 - __main__ - INFO - Epoch 4, Batch 0, Loss: 11.5186
2026-02-09 20:30:11,736 - __main__ - INFO - Epoch 4, Batch 50, Loss: 14.5350
2026-02-09 20:30:11,938 - __main__ - INFO - Epoch 4, Batch 100, Loss: 13.0830
2026-02-09 20:30:12,140 - __main__ - INFO - Epoch 4, Batch 150, Loss: 12.3428
2026-02-09 20:30:12,336 - __main__ - INFO - Epoch 4, Batch 200, Loss: 14.8034
2026-02-09 20:30:12,534 - __main__ - INFO - Epoch 4, Batch 250, Loss: 13.1363
2026-02-09 20:30:12,739 - __main__ - INFO - Epoch 4, Batch 300, Loss: 13.5016
2026-02-09 20:30:13,084 - __main__ - INFO - Epoch 4: Train Loss: 13.0884, Val Loss: 15.8771
2026-02-09 20:30:13,210 - __main__ - INFO - Epoch 5, Batch 0, Loss: 16.0576
2026-02-09 20:30:13,414 - __main__ - INFO - Epoch 5, Batch 50, Loss: 13.0715
2026-02-09 20:30:13,650 - __main__ - INFO - Epoch 5, Batch 100, Loss: 12.6684
2026-02-09 20:30:13,866 - __main__ - INFO - Epoch 5, Batch 150, Loss: 12.8351
2026-02-09 20:30:14,066 - __main__ - INFO - Epoch 5, Batch 200, Loss: 13.4759
2026-02-09 20:30:14,270 - __main__ - INFO - Epoch 5, Batch 250, Loss: 13.0466
2026-02-09 20:30:14,480 - __main__ - INFO - Epoch 5, Batch 300, Loss: 14.7571
2026-02-09 20:30:14,826 - __main__ - INFO - Epoch 5: Train Loss: 13.0915, Val Loss: 15.4574
2026-02-09 20:30:14,928 - __main__ - INFO - Epoch 6, Batch 0, Loss: 13.4335
2026-02-09 20:30:15,187 - __main__ - INFO - Epoch 6, Batch 50, Loss: 14.0772
2026-02-09 20:30:15,396 - __main__ - INFO - Epoch 6, Batch 100, Loss: 11.7078
2026-02-09 20:30:15,602 - __main__ - INFO - Epoch 6, Batch 150, Loss: 13.2576
2026-02-09 20:30:15,835 - __main__ - INFO - Epoch 6, Batch 200, Loss: 12.7263
2026-02-09 20:30:16,038 - __main__ - INFO - Epoch 6, Batch 250, Loss: 13.4626
2026-02-09 20:30:16,244 - __main__ - INFO - Epoch 6, Batch 300, Loss: 14.4801
2026-02-09 20:30:16,586 - __main__ - INFO - Epoch 6: Train Loss: 13.0766, Val Loss: 15.6400
2026-02-09 20:30:16,736 - __main__ - INFO - Epoch 7, Batch 0, Loss: 14.3549
2026-02-09 20:30:16,956 - __main__ - INFO - Epoch 7, Batch 50, Loss: 12.4234
2026-02-09 20:30:17,151 - __main__ - INFO - Epoch 7, Batch 100, Loss: 12.7857
2026-02-09 20:30:17,353 - __main__ - INFO - Epoch 7, Batch 150, Loss: 15.9146
2026-02-09 20:30:17,563 - __main__ - INFO - Epoch 7, Batch 200, Loss: 15.6115
2026-02-09 20:30:17,806 - __main__ - INFO - Epoch 7, Batch 250, Loss: 11.8901
2026-02-09 20:30:18,003 - __main__ - INFO - Epoch 7, Batch 300, Loss: 11.5825
2026-02-09 20:30:18,360 - __main__ - INFO - Epoch 7: Train Loss: 13.0692, Val Loss: 15.6386
2026-02-09 20:30:18,490 - __main__ - INFO - Epoch 8, Batch 0, Loss: 14.3384
2026-02-09 20:30:18,704 - __main__ - INFO - Epoch 8, Batch 50, Loss: 11.4083
2026-02-09 20:30:18,912 - __main__ - INFO - Epoch 8, Batch 100, Loss: 14.5733
2026-02-09 20:30:19,114 - __main__ - INFO - Epoch 8, Batch 150, Loss: 13.3135
2026-02-09 20:30:19,318 - __main__ - INFO - Epoch 8, Batch 200, Loss: 12.9706
2026-02-09 20:30:19,534 - __main__ - INFO - Epoch 8, Batch 250, Loss: 13.3688
2026-02-09 20:30:19,775 - __main__ - INFO - Epoch 8, Batch 300, Loss: 14.2943
2026-02-09 20:30:20,112 - __main__ - INFO - Epoch 8: Train Loss: 13.0322, Val Loss: 15.6669
2026-02-09 20:30:20,240 - __main__ - INFO - Epoch 9, Batch 0, Loss: 12.3675
2026-02-09 20:30:20,443 - __main__ - INFO - Epoch 9, Batch 50, Loss: 13.1432
2026-02-09 20:30:20,657 - __main__ - INFO - Epoch 9, Batch 100, Loss: 12.3565
2026-02-09 20:30:20,861 - __main__ - INFO - Epoch 9, Batch 150, Loss: 12.8332
2026-02-09 20:30:21,059 - __main__ - INFO - Epoch 9, Batch 200, Loss: 12.8327
2026-02-09 20:30:21,255 - __main__ - INFO - Epoch 9, Batch 250, Loss: 14.1901
2026-02-09 20:30:21,454 - __main__ - INFO - Epoch 9, Batch 300, Loss: 12.7301
2026-02-09 20:30:21,822 - __main__ - INFO - Epoch 9: Train Loss: 13.0430, Val Loss: 15.8081
2026-02-09 20:30:21,947 - __main__ - INFO - Epoch 10, Batch 0, Loss: 13.3931
2026-02-09 20:30:22,146 - __main__ - INFO - Epoch 10, Batch 50, Loss: 13.4121
2026-02-09 20:30:22,345 - __main__ - INFO - Epoch 10, Batch 100, Loss: 12.6559
2026-02-09 20:30:22,560 - __main__ - INFO - Epoch 10, Batch 150, Loss: 12.2954
2026-02-09 20:30:22,786 - __main__ - INFO - Epoch 10, Batch 200, Loss: 12.6175
2026-02-09 20:30:22,990 - __main__ - INFO - Epoch 10, Batch 250, Loss: 13.3965
2026-02-09 20:30:23,192 - __main__ - INFO - Epoch 10, Batch 300, Loss: 11.7942
2026-02-09 20:30:23,532 - __main__ - INFO - Epoch 10: Train Loss: 13.0584, Val Loss: 16.5016
2026-02-09 20:30:23,707 - __main__ - INFO - Epoch 11, Batch 0, Loss: 13.1087
2026-02-09 20:30:23,904 - __main__ - INFO - Epoch 11, Batch 50, Loss: 12.2815
2026-02-09 20:30:24,120 - __main__ - INFO - Epoch 11, Batch 100, Loss: 14.5169
2026-02-09 20:30:24,320 - __main__ - INFO - Epoch 11, Batch 150, Loss: 12.4626
2026-02-09 20:30:24,528 - __main__ - INFO - Epoch 11, Batch 200, Loss: 13.6870
2026-02-09 20:30:24,749 - __main__ - INFO - Epoch 11, Batch 250, Loss: 14.7497
2026-02-09 20:30:24,962 - __main__ - INFO - Epoch 11, Batch 300, Loss: 14.0413
2026-02-09 20:30:25,295 - __main__ - INFO - Epoch 11: Train Loss: 13.0236, Val Loss: 15.9433
2026-02-09 20:30:25,413 - __main__ - INFO - Epoch 12, Batch 0, Loss: 13.0214
2026-02-09 20:30:25,623 - __main__ - INFO - Epoch 12, Batch 50, Loss: 11.5932
2026-02-09 20:30:25,857 - __main__ - INFO - Epoch 12, Batch 100, Loss: 12.6162
2026-02-09 20:30:26,071 - __main__ - INFO - Epoch 12, Batch 150, Loss: 13.3586
2026-02-09 20:30:26,271 - __main__ - INFO - Epoch 12, Batch 200, Loss: 14.2356
2026-02-09 20:30:26,470 - __main__ - INFO - Epoch 12, Batch 250, Loss: 13.5355
2026-02-09 20:30:26,688 - __main__ - INFO - Epoch 12, Batch 300, Loss: 11.6894
2026-02-09 20:30:27,038 - __main__ - INFO - Epoch 12: Train Loss: 13.0673, Val Loss: 16.3390
2026-02-09 20:30:27,158 - __main__ - INFO - Epoch 13, Batch 0, Loss: 11.4465
2026-02-09 20:30:27,363 - __main__ - INFO - Epoch 13, Batch 50, Loss: 13.6140
2026-02-09 20:30:27,567 - __main__ - INFO - Epoch 13, Batch 100, Loss: 11.8302
2026-02-09 20:30:27,825 - __main__ - INFO - Epoch 13, Batch 150, Loss: 12.6139
2026-02-09 20:30:28,037 - __main__ - INFO - Epoch 13, Batch 200, Loss: 12.2840
2026-02-09 20:30:28,237 - __main__ - INFO - Epoch 13, Batch 250, Loss: 10.8162
2026-02-09 20:30:28,447 - __main__ - INFO - Epoch 13, Batch 300, Loss: 12.5705
2026-02-09 20:30:28,780 - __main__ - INFO - Epoch 13: Train Loss: 13.0300, Val Loss: 15.5707
2026-02-09 20:30:28,878 - __main__ - INFO - Epoch 14, Batch 0, Loss: 13.6742
2026-02-09 20:30:29,094 - __main__ - INFO - Epoch 14, Batch 50, Loss: 12.0809
2026-02-09 20:30:29,302 - __main__ - INFO - Epoch 14, Batch 100, Loss: 12.1936
2026-02-09 20:30:29,513 - __main__ - INFO - Epoch 14, Batch 150, Loss: 13.5375
2026-02-09 20:30:29,756 - __main__ - INFO - Epoch 14, Batch 200, Loss: 13.1412
2026-02-09 20:30:29,965 - __main__ - INFO - Epoch 14, Batch 250, Loss: 12.0665
2026-02-09 20:30:30,166 - __main__ - INFO - Epoch 14, Batch 300, Loss: 15.3975
2026-02-09 20:30:30,488 - __main__ - INFO - Epoch 14: Train Loss: 13.0461, Val Loss: 16.3456
2026-02-09 20:30:30,606 - __main__ - INFO - Epoch 15, Batch 0, Loss: 13.0908
2026-02-09 20:30:30,816 - __main__ - INFO - Epoch 15, Batch 50, Loss: 13.8681
2026-02-09 20:30:31,013 - __main__ - INFO - Epoch 15, Batch 100, Loss: 12.7172
2026-02-09 20:30:31,221 - __main__ - INFO - Epoch 15, Batch 150, Loss: 11.6883
2026-02-09 20:30:31,423 - __main__ - INFO - Epoch 15, Batch 200, Loss: 13.3506
2026-02-09 20:30:31,639 - __main__ - INFO - Epoch 15, Batch 250, Loss: 14.2465
2026-02-09 20:30:31,868 - __main__ - INFO - Epoch 15, Batch 300, Loss: 13.5403
2026-02-09 20:30:32,210 - __main__ - INFO - Epoch 15: Train Loss: 13.0579, Val Loss: 15.5361
2026-02-09 20:30:32,324 - __main__ - INFO - Epoch 16, Batch 0, Loss: 14.5251
2026-02-09 20:30:32,523 - __main__ - INFO - Epoch 16, Batch 50, Loss: 12.7848
2026-02-09 20:30:32,735 - __main__ - INFO - Epoch 16, Batch 100, Loss: 12.5423
2026-02-09 20:30:32,946 - __main__ - INFO - Epoch 16, Batch 150, Loss: 13.8240
2026-02-09 20:30:33,159 - __main__ - INFO - Epoch 16, Batch 200, Loss: 13.2208
2026-02-09 20:30:33,361 - __main__ - INFO - Epoch 16, Batch 250, Loss: 12.4313
2026-02-09 20:30:33,583 - __main__ - INFO - Epoch 16, Batch 300, Loss: 11.7154
2026-02-09 20:30:33,936 - __main__ - INFO - Epoch 16: Train Loss: 13.0464, Val Loss: 15.6655
2026-02-09 20:30:34,051 - __main__ - INFO - Epoch 17, Batch 0, Loss: 13.8411
2026-02-09 20:30:34,250 - __main__ - INFO - Epoch 17, Batch 50, Loss: 13.9883
2026-02-09 20:30:34,449 - __main__ - INFO - Epoch 17, Batch 100, Loss: 13.4532
2026-02-09 20:30:34,675 - __main__ - INFO - Epoch 17, Batch 150, Loss: 12.8464
2026-02-09 20:30:34,875 - __main__ - INFO - Epoch 17, Batch 200, Loss: 14.3972
2026-02-09 20:30:35,077 - __main__ - INFO - Epoch 17, Batch 250, Loss: 12.6200
2026-02-09 20:30:35,289 - __main__ - INFO - Epoch 17, Batch 300, Loss: 12.7029
2026-02-09 20:30:35,645 - __main__ - INFO - Epoch 17: Train Loss: 13.0570, Val Loss: 15.7427
2026-02-09 20:30:35,768 - __main__ - INFO - Epoch 18, Batch 0, Loss: 14.1960
2026-02-09 20:30:35,974 - __main__ - INFO - Epoch 18, Batch 50, Loss: 15.6215
2026-02-09 20:30:36,172 - __main__ - INFO - Epoch 18, Batch 100, Loss: 14.6942
2026-02-09 20:30:36,387 - __main__ - INFO - Epoch 18, Batch 150, Loss: 13.1839
2026-02-09 20:30:36,586 - __main__ - INFO - Epoch 18, Batch 200, Loss: 12.3185
2026-02-09 20:30:36,800 - __main__ - INFO - Epoch 18, Batch 250, Loss: 14.0886
2026-02-09 20:30:37,009 - __main__ - INFO - Epoch 18, Batch 300, Loss: 12.9455
2026-02-09 20:30:37,355 - __main__ - INFO - Epoch 18: Train Loss: 13.0548, Val Loss: 15.6654
2026-02-09 20:30:37,472 - __main__ - INFO - Epoch 19, Batch 0, Loss: 14.0995
2026-02-09 20:30:37,728 - __main__ - INFO - Epoch 19, Batch 50, Loss: 13.9962
2026-02-09 20:30:37,932 - __main__ - INFO - Epoch 19, Batch 100, Loss: 13.9111
2026-02-09 20:30:38,143 - __main__ - INFO - Epoch 19, Batch 150, Loss: 13.3696
2026-02-09 20:30:38,346 - __main__ - INFO - Epoch 19, Batch 200, Loss: 10.8520
2026-02-09 20:30:38,546 - __main__ - INFO - Epoch 19, Batch 250, Loss: 13.2476
2026-02-09 20:30:38,753 - __main__ - INFO - Epoch 19, Batch 300, Loss: 13.7975
2026-02-09 20:30:39,073 - __main__ - INFO - Epoch 19: Train Loss: 13.0167, Val Loss: 15.7452
2026-02-09 20:30:39,192 - __main__ - INFO - Epoch 20, Batch 0, Loss: 11.6998
2026-02-09 20:30:39,409 - __main__ - INFO - Epoch 20, Batch 50, Loss: 12.9320
2026-02-09 20:30:39,615 - __main__ - INFO - Epoch 20, Batch 100, Loss: 12.5773
2026-02-09 20:30:39,873 - __main__ - INFO - Epoch 20, Batch 150, Loss: 12.4266
2026-02-09 20:30:40,068 - __main__ - INFO - Epoch 20, Batch 200, Loss: 12.6520
2026-02-09 20:30:40,271 - __main__ - INFO - Epoch 20, Batch 250, Loss: 12.0306
2026-02-09 20:30:40,494 - __main__ - INFO - Epoch 20, Batch 300, Loss: 11.8092
2026-02-09 20:30:40,832 - __main__ - INFO - Epoch 20: Train Loss: 13.0488, Val Loss: 15.9444
2026-02-09 20:30:40,933 - __main__ - INFO - Epoch 21, Batch 0, Loss: 12.6934
2026-02-09 20:30:41,167 - __main__ - INFO - Epoch 21, Batch 50, Loss: 13.0273
2026-02-09 20:30:41,365 - __main__ - INFO - Epoch 21, Batch 100, Loss: 11.2398
2026-02-09 20:30:41,575 - __main__ - INFO - Epoch 21, Batch 150, Loss: 13.1529
2026-02-09 20:30:41,808 - __main__ - INFO - Epoch 21, Batch 200, Loss: 16.0418
2026-02-09 20:30:42,000 - __main__ - INFO - Epoch 21, Batch 250, Loss: 14.4546
2026-02-09 20:30:42,200 - __main__ - INFO - Epoch 21, Batch 300, Loss: 13.3505
2026-02-09 20:30:42,521 - __main__ - INFO - Epoch 21: Train Loss: 13.0496, Val Loss: 15.3717
2026-02-09 20:30:42,651 - __main__ - INFO - Epoch 22, Batch 0, Loss: 14.3317
2026-02-09 20:30:42,852 - __main__ - INFO - Epoch 22, Batch 50, Loss: 12.7628
2026-02-09 20:30:43,052 - __main__ - INFO - Epoch 22, Batch 100, Loss: 12.9705
2026-02-09 20:30:43,265 - __main__ - INFO - Epoch 22, Batch 150, Loss: 12.2217
2026-02-09 20:30:43,465 - __main__ - INFO - Epoch 22, Batch 200, Loss: 13.1458
2026-02-09 20:30:43,718 - __main__ - INFO - Epoch 22, Batch 250, Loss: 11.0271
2026-02-09 20:30:43,931 - __main__ - INFO - Epoch 22, Batch 300, Loss: 13.0689
2026-02-09 20:30:44,256 - __main__ - INFO - Epoch 22: Train Loss: 13.0451, Val Loss: 15.4132
2026-02-09 20:30:44,374 - __main__ - INFO - Epoch 23, Batch 0, Loss: 13.3576
2026-02-09 20:30:44,585 - __main__ - INFO - Epoch 23, Batch 50, Loss: 13.0380
2026-02-09 20:30:44,800 - __main__ - INFO - Epoch 23, Batch 100, Loss: 13.7753
2026-02-09 20:30:45,009 - __main__ - INFO - Epoch 23, Batch 150, Loss: 14.3969
2026-02-09 20:30:45,206 - __main__ - INFO - Epoch 23, Batch 200, Loss: 11.2243
2026-02-09 20:30:45,405 - __main__ - INFO - Epoch 23, Batch 250, Loss: 11.9860
2026-02-09 20:30:45,609 - __main__ - INFO - Epoch 23, Batch 300, Loss: 11.2470
2026-02-09 20:30:45,959 - __main__ - INFO - Epoch 23: Train Loss: 13.0303, Val Loss: 15.4848
2026-02-09 20:30:46,060 - __main__ - INFO - Epoch 24, Batch 0, Loss: 12.5726
2026-02-09 20:30:46,289 - __main__ - INFO - Epoch 24, Batch 50, Loss: 12.8419
2026-02-09 20:30:46,512 - __main__ - INFO - Epoch 24, Batch 100, Loss: 13.6521
2026-02-09 20:30:46,740 - __main__ - INFO - Epoch 24, Batch 150, Loss: 13.3067
2026-02-09 20:30:46,938 - __main__ - INFO - Epoch 24, Batch 200, Loss: 13.0175
2026-02-09 20:30:47,142 - __main__ - INFO - Epoch 24, Batch 250, Loss: 10.8300
2026-02-09 20:30:47,349 - __main__ - INFO - Epoch 24, Batch 300, Loss: 13.4767
2026-02-09 20:30:47,703 - __main__ - INFO - Epoch 24: Train Loss: 13.0128, Val Loss: 15.6905
2026-02-09 20:30:47,832 - __main__ - INFO - Epoch 25, Batch 0, Loss: 13.4657
2026-02-09 20:30:48,034 - __main__ - INFO - Epoch 25, Batch 50, Loss: 12.4665
2026-02-09 20:30:48,251 - __main__ - INFO - Epoch 25, Batch 100, Loss: 14.7677
2026-02-09 20:30:48,475 - __main__ - INFO - Epoch 25, Batch 150, Loss: 13.6912
2026-02-09 20:30:48,703 - __main__ - INFO - Epoch 25, Batch 200, Loss: 11.7960
2026-02-09 20:30:48,905 - __main__ - INFO - Epoch 25, Batch 250, Loss: 13.0257
2026-02-09 20:30:49,106 - __main__ - INFO - Epoch 25, Batch 300, Loss: 10.6482
2026-02-09 20:30:49,435 - __main__ - INFO - Epoch 25: Train Loss: 13.0511, Val Loss: 15.8153
2026-02-09 20:30:49,551 - __main__ - INFO - Epoch 26, Batch 0, Loss: 12.7529
2026-02-09 20:30:49,800 - __main__ - INFO - Epoch 26, Batch 50, Loss: 13.2251
2026-02-09 20:30:50,007 - __main__ - INFO - Epoch 26, Batch 100, Loss: 12.8263
2026-02-09 20:30:50,222 - __main__ - INFO - Epoch 26, Batch 150, Loss: 12.9867
2026-02-09 20:30:50,422 - __main__ - INFO - Epoch 26, Batch 200, Loss: 14.9489
2026-02-09 20:30:50,639 - __main__ - INFO - Epoch 26, Batch 250, Loss: 12.4161
2026-02-09 20:30:50,862 - __main__ - INFO - Epoch 26, Batch 300, Loss: 13.2528
2026-02-09 20:30:51,190 - __main__ - INFO - Epoch 26: Train Loss: 13.0056, Val Loss: 15.4093
2026-02-09 20:30:51,306 - __main__ - INFO - Epoch 27, Batch 0, Loss: 10.9524
2026-02-09 20:30:51,518 - __main__ - INFO - Epoch 27, Batch 50, Loss: 15.0265
2026-02-09 20:30:51,756 - __main__ - INFO - Epoch 27, Batch 100, Loss: 12.7265
2026-02-09 20:30:51,972 - __main__ - INFO - Epoch 27, Batch 150, Loss: 13.6273
2026-02-09 20:30:52,169 - __main__ - INFO - Epoch 27, Batch 200, Loss: 12.4703
2026-02-09 20:30:52,384 - __main__ - INFO - Epoch 27, Batch 250, Loss: 12.2157
2026-02-09 20:30:52,593 - __main__ - INFO - Epoch 27, Batch 300, Loss: 13.9056
2026-02-09 20:30:52,944 - __main__ - INFO - Epoch 27: Train Loss: 13.0319, Val Loss: 15.6287
2026-02-09 20:30:53,058 - __main__ - INFO - Epoch 28, Batch 0, Loss: 12.5563
2026-02-09 20:30:53,273 - __main__ - INFO - Epoch 28, Batch 50, Loss: 11.7796
2026-02-09 20:30:53,493 - __main__ - INFO - Epoch 28, Batch 100, Loss: 14.4935
2026-02-09 20:30:53,746 - __main__ - INFO - Epoch 28, Batch 150, Loss: 13.7411
2026-02-09 20:30:53,951 - __main__ - INFO - Epoch 28, Batch 200, Loss: 13.4846
2026-02-09 20:30:54,144 - __main__ - INFO - Epoch 28, Batch 250, Loss: 12.1947
2026-02-09 20:30:54,348 - __main__ - INFO - Epoch 28, Batch 300, Loss: 13.3841
2026-02-09 20:30:54,696 - __main__ - INFO - Epoch 28: Train Loss: 13.0285, Val Loss: 15.6819
2026-02-09 20:30:54,818 - __main__ - INFO - Epoch 29, Batch 0, Loss: 12.7161
2026-02-09 20:30:55,016 - __main__ - INFO - Epoch 29, Batch 50, Loss: 13.7263
2026-02-09 20:30:55,214 - __main__ - INFO - Epoch 29, Batch 100, Loss: 11.8029
2026-02-09 20:30:55,432 - __main__ - INFO - Epoch 29, Batch 150, Loss: 12.0333
2026-02-09 20:30:55,647 - __main__ - INFO - Epoch 29, Batch 200, Loss: 11.9101
2026-02-09 20:30:55,883 - __main__ - INFO - Epoch 29, Batch 250, Loss: 14.4886
2026-02-09 20:30:56,079 - __main__ - INFO - Epoch 29, Batch 300, Loss: 12.1566
2026-02-09 20:30:56,409 - __main__ - INFO - Epoch 29: Train Loss: 13.0317, Val Loss: 16.1585
2026-02-09 20:30:56,528 - __main__ - INFO - Epoch 30, Batch 0, Loss: 13.1799
2026-02-09 20:30:56,744 - __main__ - INFO - Epoch 30, Batch 50, Loss: 11.8696
2026-02-09 20:30:56,985 - __main__ - INFO - Epoch 30, Batch 100, Loss: 11.9101
2026-02-09 20:30:57,199 - __main__ - INFO - Epoch 30, Batch 150, Loss: 12.7382
2026-02-09 20:30:57,406 - __main__ - INFO - Epoch 30, Batch 200, Loss: 12.4805
2026-02-09 20:30:57,610 - __main__ - INFO - Epoch 30, Batch 250, Loss: 11.6580
2026-02-09 20:30:57,868 - __main__ - INFO - Epoch 30, Batch 300, Loss: 10.9791
2026-02-09 20:30:58,210 - __main__ - INFO - Epoch 30: Train Loss: 13.0209, Val Loss: 15.3484
2026-02-09 20:30:58,309 - __main__ - INFO - Epoch 31, Batch 0, Loss: 12.9840
2026-02-09 20:30:58,539 - __main__ - INFO - Epoch 31, Batch 50, Loss: 13.6056
2026-02-09 20:30:58,757 - __main__ - INFO - Epoch 31, Batch 100, Loss: 13.3401
2026-02-09 20:30:58,970 - __main__ - INFO - Epoch 31, Batch 150, Loss: 12.2779
2026-02-09 20:30:59,172 - __main__ - INFO - Epoch 31, Batch 200, Loss: 13.3614
2026-02-09 20:30:59,372 - __main__ - INFO - Epoch 31, Batch 250, Loss: 14.8942
2026-02-09 20:30:59,610 - __main__ - INFO - Epoch 31, Batch 300, Loss: 13.7474
2026-02-09 20:30:59,974 - __main__ - INFO - Epoch 31: Train Loss: 12.9984, Val Loss: 16.4530
2026-02-09 20:31:00,094 - __main__ - INFO - Epoch 32, Batch 0, Loss: 13.1194
2026-02-09 20:31:00,303 - __main__ - INFO - Epoch 32, Batch 50, Loss: 11.4339
2026-02-09 20:31:00,503 - __main__ - INFO - Epoch 32, Batch 100, Loss: 14.0160
2026-02-09 20:31:00,774 - __main__ - INFO - Epoch 32, Batch 150, Loss: 12.1916
2026-02-09 20:31:00,981 - __main__ - INFO - Epoch 32, Batch 200, Loss: 12.0157
2026-02-09 20:31:01,185 - __main__ - INFO - Epoch 32, Batch 250, Loss: 13.9578
2026-02-09 20:31:01,386 - __main__ - INFO - Epoch 32, Batch 300, Loss: 11.9109
2026-02-09 20:31:01,759 - __main__ - INFO - Epoch 32: Train Loss: 13.0167, Val Loss: 15.6489
2026-02-09 20:31:01,873 - __main__ - INFO - Epoch 33, Batch 0, Loss: 11.9799
2026-02-09 20:31:02,083 - __main__ - INFO - Epoch 33, Batch 50, Loss: 13.4968
2026-02-09 20:31:02,280 - __main__ - INFO - Epoch 33, Batch 100, Loss: 11.3907
2026-02-09 20:31:02,491 - __main__ - INFO - Epoch 33, Batch 150, Loss: 13.8991
2026-02-09 20:31:02,714 - __main__ - INFO - Epoch 33, Batch 200, Loss: 11.4077
2026-02-09 20:31:02,926 - __main__ - INFO - Epoch 33, Batch 250, Loss: 13.0844
2026-02-09 20:31:03,118 - __main__ - INFO - Epoch 33, Batch 300, Loss: 12.3380
2026-02-09 20:31:03,474 - __main__ - INFO - Epoch 33: Train Loss: 13.0155, Val Loss: 15.8284
2026-02-09 20:31:03,594 - __main__ - INFO - Epoch 34, Batch 0, Loss: 14.0881
2026-02-09 20:31:03,830 - __main__ - INFO - Epoch 34, Batch 50, Loss: 11.7993
2026-02-09 20:31:04,039 - __main__ - INFO - Epoch 34, Batch 100, Loss: 12.5012
2026-02-09 20:31:04,245 - __main__ - INFO - Epoch 34, Batch 150, Loss: 13.1262
2026-02-09 20:31:04,452 - __main__ - INFO - Epoch 34, Batch 200, Loss: 13.2655
2026-02-09 20:31:04,670 - __main__ - INFO - Epoch 34, Batch 250, Loss: 13.3182
2026-02-09 20:31:04,873 - __main__ - INFO - Epoch 34, Batch 300, Loss: 12.6064
2026-02-09 20:31:05,193 - __main__ - INFO - Epoch 34: Train Loss: 13.0045, Val Loss: 15.4871
2026-02-09 20:31:05,312 - __main__ - INFO - Epoch 35, Batch 0, Loss: 17.4461
2026-02-09 20:31:05,544 - __main__ - INFO - Epoch 35, Batch 50, Loss: 12.5428
2026-02-09 20:31:05,783 - __main__ - INFO - Epoch 35, Batch 100, Loss: 12.8008
2026-02-09 20:31:05,990 - __main__ - INFO - Epoch 35, Batch 150, Loss: 15.3556
2026-02-09 20:31:06,193 - __main__ - INFO - Epoch 35, Batch 200, Loss: 13.6005
2026-02-09 20:31:06,403 - __main__ - INFO - Epoch 35, Batch 250, Loss: 11.6183
2026-02-09 20:31:06,603 - __main__ - INFO - Epoch 35, Batch 300, Loss: 12.5038
2026-02-09 20:31:06,959 - __main__ - INFO - Epoch 35: Train Loss: 12.9905, Val Loss: 15.7434
2026-02-09 20:31:07,072 - __main__ - INFO - Epoch 36, Batch 0, Loss: 13.3666
2026-02-09 20:31:07,281 - __main__ - INFO - Epoch 36, Batch 50, Loss: 11.6418
2026-02-09 20:31:07,490 - __main__ - INFO - Epoch 36, Batch 100, Loss: 14.5741
2026-02-09 20:31:07,744 - __main__ - INFO - Epoch 36, Batch 150, Loss: 11.5653
2026-02-09 20:31:07,967 - __main__ - INFO - Epoch 36, Batch 200, Loss: 12.9031
2026-02-09 20:31:08,169 - __main__ - INFO - Epoch 36, Batch 250, Loss: 12.6169
2026-02-09 20:31:08,378 - __main__ - INFO - Epoch 36, Batch 300, Loss: 12.6443
2026-02-09 20:31:08,713 - __main__ - INFO - Epoch 36: Train Loss: 13.0022, Val Loss: 15.9677
2026-02-09 20:31:08,835 - __main__ - INFO - Epoch 37, Batch 0, Loss: 11.3603
2026-02-09 20:31:09,041 - __main__ - INFO - Epoch 37, Batch 50, Loss: 13.5188
2026-02-09 20:31:09,240 - __main__ - INFO - Epoch 37, Batch 100, Loss: 11.1381
2026-02-09 20:31:09,450 - __main__ - INFO - Epoch 37, Batch 150, Loss: 12.7914
2026-02-09 20:31:09,656 - __main__ - INFO - Epoch 37, Batch 200, Loss: 12.9232
2026-02-09 20:31:09,892 - __main__ - INFO - Epoch 37, Batch 250, Loss: 12.5479
2026-02-09 20:31:10,093 - __main__ - INFO - Epoch 37, Batch 300, Loss: 10.5693
2026-02-09 20:31:10,423 - __main__ - INFO - Epoch 37: Train Loss: 13.0064, Val Loss: 15.3831
2026-02-09 20:31:10,546 - __main__ - INFO - Epoch 38, Batch 0, Loss: 12.2437
2026-02-09 20:31:10,760 - __main__ - INFO - Epoch 38, Batch 50, Loss: 12.8268
2026-02-09 20:31:10,962 - __main__ - INFO - Epoch 38, Batch 100, Loss: 10.5512
2026-02-09 20:31:11,170 - __main__ - INFO - Epoch 38, Batch 150, Loss: 11.9139
2026-02-09 20:31:11,372 - __main__ - INFO - Epoch 38, Batch 200, Loss: 13.6448
2026-02-09 20:31:11,589 - __main__ - INFO - Epoch 38, Batch 250, Loss: 12.4108
2026-02-09 20:31:11,840 - __main__ - INFO - Epoch 38, Batch 300, Loss: 14.5940
2026-02-09 20:31:12,165 - __main__ - INFO - Epoch 38: Train Loss: 12.9819, Val Loss: 16.3110
2026-02-09 20:31:12,262 - __main__ - INFO - Epoch 39, Batch 0, Loss: 12.4125
2026-02-09 20:31:12,492 - __main__ - INFO - Epoch 39, Batch 50, Loss: 12.9118
2026-02-09 20:31:12,704 - __main__ - INFO - Epoch 39, Batch 100, Loss: 11.8643
2026-02-09 20:31:12,907 - __main__ - INFO - Epoch 39, Batch 150, Loss: 13.1072
2026-02-09 20:31:13,109 - __main__ - INFO - Epoch 39, Batch 200, Loss: 12.7321
2026-02-09 20:31:13,310 - __main__ - INFO - Epoch 39, Batch 250, Loss: 12.7924
2026-02-09 20:31:13,514 - __main__ - INFO - Epoch 39, Batch 300, Loss: 12.7945
2026-02-09 20:31:13,884 - __main__ - INFO - Epoch 39: Train Loss: 13.0116, Val Loss: 15.5991
2026-02-09 20:31:14,002 - __main__ - INFO - Epoch 40, Batch 0, Loss: 12.4861
2026-02-09 20:31:14,197 - __main__ - INFO - Epoch 40, Batch 50, Loss: 13.1456
2026-02-09 20:31:14,396 - __main__ - INFO - Epoch 40, Batch 100, Loss: 12.5994
2026-02-09 20:31:14,619 - __main__ - INFO - Epoch 40, Batch 150, Loss: 13.7655
2026-02-09 20:31:14,833 - __main__ - INFO - Epoch 40, Batch 200, Loss: 16.2680
2026-02-09 20:31:15,029 - __main__ - INFO - Epoch 40, Batch 250, Loss: 13.2786
2026-02-09 20:31:15,245 - __main__ - INFO - Epoch 40, Batch 300, Loss: 12.9339
2026-02-09 20:31:15,583 - __main__ - INFO - Epoch 40: Train Loss: 12.9877, Val Loss: 15.4881
2026-02-09 20:31:15,700 - __main__ - INFO - Epoch 41, Batch 0, Loss: 11.8472
2026-02-09 20:31:15,951 - __main__ - INFO - Epoch 41, Batch 50, Loss: 13.2631
2026-02-09 20:31:16,158 - __main__ - INFO - Epoch 41, Batch 100, Loss: 12.4830
2026-02-09 20:31:16,366 - __main__ - INFO - Epoch 41, Batch 150, Loss: 12.7630
2026-02-09 20:31:16,566 - __main__ - INFO - Epoch 41, Batch 200, Loss: 14.4851
2026-02-09 20:31:16,788 - __main__ - INFO - Epoch 41, Batch 250, Loss: 12.0182
2026-02-09 20:31:17,000 - __main__ - INFO - Epoch 41, Batch 300, Loss: 11.9516
2026-02-09 20:31:17,329 - __main__ - INFO - Epoch 41: Train Loss: 12.9822, Val Loss: 16.2330
2026-02-09 20:31:17,446 - __main__ - INFO - Epoch 42, Batch 0, Loss: 12.9717
2026-02-09 20:31:17,656 - __main__ - INFO - Epoch 42, Batch 50, Loss: 12.7780
2026-02-09 20:31:17,889 - __main__ - INFO - Epoch 42, Batch 100, Loss: 11.6732
2026-02-09 20:31:18,110 - __main__ - INFO - Epoch 42, Batch 150, Loss: 11.3823
2026-02-09 20:31:18,308 - __main__ - INFO - Epoch 42, Batch 200, Loss: 14.6907
2026-02-09 20:31:18,509 - __main__ - INFO - Epoch 42, Batch 250, Loss: 12.2360
2026-02-09 20:31:18,741 - __main__ - INFO - Epoch 42, Batch 300, Loss: 13.4861
2026-02-09 20:31:19,072 - __main__ - INFO - Epoch 42: Train Loss: 12.9936, Val Loss: 15.7740
2026-02-09 20:31:19,187 - __main__ - INFO - Epoch 43, Batch 0, Loss: 12.6041
2026-02-09 20:31:19,404 - __main__ - INFO - Epoch 43, Batch 50, Loss: 12.8807
2026-02-09 20:31:19,612 - __main__ - INFO - Epoch 43, Batch 100, Loss: 13.6367
2026-02-09 20:31:19,861 - __main__ - INFO - Epoch 43, Batch 150, Loss: 13.2829
2026-02-09 20:31:20,059 - __main__ - INFO - Epoch 43, Batch 200, Loss: 12.4101
2026-02-09 20:31:20,263 - __main__ - INFO - Epoch 43, Batch 250, Loss: 13.9674
2026-02-09 20:31:20,473 - __main__ - INFO - Epoch 43, Batch 300, Loss: 13.9646
2026-02-09 20:31:20,806 - __main__ - INFO - Epoch 43: Train Loss: 12.9822, Val Loss: 15.5211
2026-02-09 20:31:20,923 - __main__ - INFO - Epoch 44, Batch 0, Loss: 13.1030
2026-02-09 20:31:21,121 - __main__ - INFO - Epoch 44, Batch 50, Loss: 13.1324
2026-02-09 20:31:21,318 - __main__ - INFO - Epoch 44, Batch 100, Loss: 14.0257
2026-02-09 20:31:21,530 - __main__ - INFO - Epoch 44, Batch 150, Loss: 14.1198
2026-02-09 20:31:21,771 - __main__ - INFO - Epoch 44, Batch 200, Loss: 14.6707
2026-02-09 20:31:21,973 - __main__ - INFO - Epoch 44, Batch 250, Loss: 11.1212
2026-02-09 20:31:22,177 - __main__ - INFO - Epoch 44, Batch 300, Loss: 14.5981
2026-02-09 20:31:22,513 - __main__ - INFO - Epoch 44: Train Loss: 13.0135, Val Loss: 15.3879
2026-02-09 20:31:22,630 - __main__ - INFO - Epoch 45, Batch 0, Loss: 14.0623
2026-02-09 20:31:22,852 - __main__ - INFO - Epoch 45, Batch 50, Loss: 11.6261
2026-02-09 20:31:23,056 - __main__ - INFO - Epoch 45, Batch 100, Loss: 15.5673
2026-02-09 20:31:23,275 - __main__ - INFO - Epoch 45, Batch 150, Loss: 12.5317
2026-02-09 20:31:23,477 - __main__ - INFO - Epoch 45, Batch 200, Loss: 12.8713
2026-02-09 20:31:23,694 - __main__ - INFO - Epoch 45, Batch 250, Loss: 12.8746
2026-02-09 20:31:23,926 - __main__ - INFO - Epoch 45, Batch 300, Loss: 13.0169
2026-02-09 20:31:24,249 - __main__ - INFO - Epoch 45: Train Loss: 12.9845, Val Loss: 15.8158
2026-02-09 20:31:24,368 - __main__ - INFO - Epoch 46, Batch 0, Loss: 13.1943
2026-02-09 20:31:24,594 - __main__ - INFO - Epoch 46, Batch 50, Loss: 13.1411
2026-02-09 20:31:24,807 - __main__ - INFO - Epoch 46, Batch 100, Loss: 13.3537
2026-02-09 20:31:25,021 - __main__ - INFO - Epoch 46, Batch 150, Loss: 14.4299
2026-02-09 20:31:25,223 - __main__ - INFO - Epoch 46, Batch 200, Loss: 14.5003
2026-02-09 20:31:25,426 - __main__ - INFO - Epoch 46, Batch 250, Loss: 12.5626
2026-02-09 20:31:25,645 - __main__ - INFO - Epoch 46, Batch 300, Loss: 14.1759
2026-02-09 20:31:26,017 - __main__ - INFO - Epoch 46: Train Loss: 12.9886, Val Loss: 15.7880
2026-02-09 20:31:26,152 - __main__ - INFO - Epoch 47, Batch 0, Loss: 13.6687
2026-02-09 20:31:26,365 - __main__ - INFO - Epoch 47, Batch 50, Loss: 12.0397
2026-02-09 20:31:26,592 - __main__ - INFO - Epoch 47, Batch 100, Loss: 15.1439
2026-02-09 20:31:26,836 - __main__ - INFO - Epoch 47, Batch 150, Loss: 13.8105
2026-02-09 20:31:27,048 - __main__ - INFO - Epoch 47, Batch 200, Loss: 12.7129
2026-02-09 20:31:27,256 - __main__ - INFO - Epoch 47, Batch 250, Loss: 12.3690
2026-02-09 20:31:27,460 - __main__ - INFO - Epoch 47, Batch 300, Loss: 12.0191
2026-02-09 20:31:27,840 - __main__ - INFO - Epoch 47: Train Loss: 12.9766, Val Loss: 15.6631
2026-02-09 20:31:27,955 - __main__ - INFO - Epoch 48, Batch 0, Loss: 12.7807
2026-02-09 20:31:28,170 - __main__ - INFO - Epoch 48, Batch 50, Loss: 12.4319
2026-02-09 20:31:28,379 - __main__ - INFO - Epoch 48, Batch 100, Loss: 13.4591
2026-02-09 20:31:28,602 - __main__ - INFO - Epoch 48, Batch 150, Loss: 13.3966
2026-02-09 20:31:28,825 - __main__ - INFO - Epoch 48, Batch 200, Loss: 14.8406
2026-02-09 20:31:29,052 - __main__ - INFO - Epoch 48, Batch 250, Loss: 12.3870
2026-02-09 20:31:29,257 - __main__ - INFO - Epoch 48, Batch 300, Loss: 12.9945
2026-02-09 20:31:29,587 - __main__ - INFO - Epoch 48: Train Loss: 12.9943, Val Loss: 15.5278
2026-02-09 20:31:29,711 - __main__ - INFO - Epoch 49, Batch 0, Loss: 12.6789
2026-02-09 20:31:29,960 - __main__ - INFO - Epoch 49, Batch 50, Loss: 12.9412
2026-02-09 20:31:30,176 - __main__ - INFO - Epoch 49, Batch 100, Loss: 11.9639
2026-02-09 20:31:30,393 - __main__ - INFO - Epoch 49, Batch 150, Loss: 12.5889
2026-02-09 20:31:30,602 - __main__ - INFO - Epoch 49, Batch 200, Loss: 13.8375
2026-02-09 20:31:30,832 - __main__ - INFO - Epoch 49, Batch 250, Loss: 13.8267
2026-02-09 20:31:31,039 - __main__ - INFO - Epoch 49, Batch 300, Loss: 12.4357
2026-02-09 20:31:31,396 - __main__ - INFO - Epoch 49: Train Loss: 13.0004, Val Loss: 15.4754
2026-02-09 20:31:31,513 - __main__ - INFO - Epoch 50, Batch 0, Loss: 14.1714
2026-02-09 20:31:31,779 - __main__ - INFO - Epoch 50, Batch 50, Loss: 13.5270
2026-02-09 20:31:31,991 - __main__ - INFO - Epoch 50, Batch 100, Loss: 13.1389
2026-02-09 20:31:32,221 - __main__ - INFO - Epoch 50, Batch 150, Loss: 11.5046
2026-02-09 20:31:32,436 - __main__ - INFO - Epoch 50, Batch 200, Loss: 12.5142
2026-02-09 20:31:32,643 - __main__ - INFO - Epoch 50, Batch 250, Loss: 12.4178
2026-02-09 20:31:32,879 - __main__ - INFO - Epoch 50, Batch 300, Loss: 10.7165
2026-02-09 20:31:33,201 - __main__ - INFO - Epoch 50: Train Loss: 12.9943, Val Loss: 15.7047
2026-02-09 20:31:33,318 - __main__ - INFO - Epoch 51, Batch 0, Loss: 14.2801
2026-02-09 20:31:33,531 - __main__ - INFO - Epoch 51, Batch 50, Loss: 13.7620
2026-02-09 20:31:33,792 - __main__ - INFO - Epoch 51, Batch 100, Loss: 11.4707
2026-02-09 20:31:34,022 - __main__ - INFO - Epoch 51, Batch 150, Loss: 12.7745
2026-02-09 20:31:34,228 - __main__ - INFO - Epoch 51, Batch 200, Loss: 13.3219
2026-02-09 20:31:34,434 - __main__ - INFO - Epoch 51, Batch 250, Loss: 12.2857
2026-02-09 20:31:34,654 - __main__ - INFO - Epoch 51, Batch 300, Loss: 12.1357
2026-02-09 20:31:35,004 - __main__ - INFO - Epoch 51: Train Loss: 12.9684, Val Loss: 15.5151
2026-02-09 20:31:35,125 - __main__ - INFO - Epoch 52, Batch 0, Loss: 12.6817
2026-02-09 20:31:35,344 - __main__ - INFO - Epoch 52, Batch 50, Loss: 12.9863
2026-02-09 20:31:35,563 - __main__ - INFO - Epoch 52, Batch 100, Loss: 13.5176
2026-02-09 20:31:35,822 - __main__ - INFO - Epoch 52, Batch 150, Loss: 14.3647
2026-02-09 20:31:36,025 - __main__ - INFO - Epoch 52, Batch 200, Loss: 14.1039
2026-02-09 20:31:36,235 - __main__ - INFO - Epoch 52, Batch 250, Loss: 11.3111
2026-02-09 20:31:36,459 - __main__ - INFO - Epoch 52, Batch 300, Loss: 14.0554
2026-02-09 20:31:36,805 - __main__ - INFO - Epoch 52: Train Loss: 12.9740, Val Loss: 15.6729
2026-02-09 20:31:36,900 - __main__ - INFO - Epoch 53, Batch 0, Loss: 14.5188
2026-02-09 20:31:37,151 - __main__ - INFO - Epoch 53, Batch 50, Loss: 12.4518
2026-02-09 20:31:37,362 - __main__ - INFO - Epoch 53, Batch 100, Loss: 13.7766
2026-02-09 20:31:37,584 - __main__ - INFO - Epoch 53, Batch 150, Loss: 13.9346
2026-02-09 20:31:37,830 - __main__ - INFO - Epoch 53, Batch 200, Loss: 10.8685
2026-02-09 20:31:38,049 - __main__ - INFO - Epoch 53, Batch 250, Loss: 12.2667
2026-02-09 20:31:38,262 - __main__ - INFO - Epoch 53, Batch 300, Loss: 12.5446
2026-02-09 20:31:38,594 - __main__ - INFO - Epoch 53: Train Loss: 12.9622, Val Loss: 15.7921
2026-02-09 20:31:38,720 - __main__ - INFO - Epoch 54, Batch 0, Loss: 12.9826
2026-02-09 20:31:38,932 - __main__ - INFO - Epoch 54, Batch 50, Loss: 11.1522
2026-02-09 20:31:39,142 - __main__ - INFO - Epoch 54, Batch 100, Loss: 13.0848
2026-02-09 20:31:39,354 - __main__ - INFO - Epoch 54, Batch 150, Loss: 14.6782
2026-02-09 20:31:39,574 - __main__ - INFO - Epoch 54, Batch 200, Loss: 13.8396
2026-02-09 20:31:39,835 - __main__ - INFO - Epoch 54, Batch 250, Loss: 12.4859
2026-02-09 20:31:40,044 - __main__ - INFO - Epoch 54, Batch 300, Loss: 13.2607
2026-02-09 20:31:40,389 - __main__ - INFO - Epoch 54: Train Loss: 12.9685, Val Loss: 15.4416
2026-02-09 20:31:40,504 - __main__ - INFO - Epoch 55, Batch 0, Loss: 12.8078
2026-02-09 20:31:40,740 - __main__ - INFO - Epoch 55, Batch 50, Loss: 12.7574
2026-02-09 20:31:40,956 - __main__ - INFO - Epoch 55, Batch 100, Loss: 13.4101
2026-02-09 20:31:41,172 - __main__ - INFO - Epoch 55, Batch 150, Loss: 13.4914
2026-02-09 20:31:41,377 - __main__ - INFO - Epoch 55, Batch 200, Loss: 14.7667
2026-02-09 20:31:41,586 - __main__ - INFO - Epoch 55, Batch 250, Loss: 12.3913
2026-02-09 20:31:41,838 - __main__ - INFO - Epoch 55, Batch 300, Loss: 12.9000
2026-02-09 20:31:42,167 - __main__ - INFO - Epoch 55: Train Loss: 12.9785, Val Loss: 15.6395
2026-02-09 20:31:42,285 - __main__ - INFO - Epoch 56, Batch 0, Loss: 13.1504
2026-02-09 20:31:42,494 - __main__ - INFO - Epoch 56, Batch 50, Loss: 12.4985
2026-02-09 20:31:42,729 - __main__ - INFO - Epoch 56, Batch 100, Loss: 13.3363
2026-02-09 20:31:42,946 - __main__ - INFO - Epoch 56, Batch 150, Loss: 13.2717
2026-02-09 20:31:43,157 - __main__ - INFO - Epoch 56, Batch 200, Loss: 11.6562
2026-02-09 20:31:43,366 - __main__ - INFO - Epoch 56, Batch 250, Loss: 13.3022
2026-02-09 20:31:43,573 - __main__ - INFO - Epoch 56, Batch 300, Loss: 13.3988
2026-02-09 20:31:43,921 - __main__ - INFO - Epoch 56: Train Loss: 12.9740, Val Loss: 15.4415
2026-02-09 20:31:44,031 - __main__ - INFO - Epoch 57, Batch 0, Loss: 12.7116
2026-02-09 20:31:44,240 - __main__ - INFO - Epoch 57, Batch 50, Loss: 11.4553
2026-02-09 20:31:44,448 - __main__ - INFO - Epoch 57, Batch 100, Loss: 12.7888
2026-02-09 20:31:44,673 - __main__ - INFO - Epoch 57, Batch 150, Loss: 12.5417
2026-02-09 20:31:44,908 - __main__ - INFO - Epoch 57, Batch 200, Loss: 13.0045
2026-02-09 20:31:45,117 - __main__ - INFO - Epoch 57, Batch 250, Loss: 12.0167
2026-02-09 20:31:45,327 - __main__ - INFO - Epoch 57, Batch 300, Loss: 12.1583
2026-02-09 20:31:45,671 - __main__ - INFO - Epoch 57: Train Loss: 12.9975, Val Loss: 15.7406
2026-02-09 20:31:45,809 - __main__ - INFO - Epoch 58, Batch 0, Loss: 12.2472
2026-02-09 20:31:46,021 - __main__ - INFO - Epoch 58, Batch 50, Loss: 13.3593
2026-02-09 20:31:46,238 - __main__ - INFO - Epoch 58, Batch 100, Loss: 11.9860
2026-02-09 20:31:46,456 - __main__ - INFO - Epoch 58, Batch 150, Loss: 11.6580
2026-02-09 20:31:46,670 - __main__ - INFO - Epoch 58, Batch 200, Loss: 14.4550
2026-02-09 20:31:46,904 - __main__ - INFO - Epoch 58, Batch 250, Loss: 14.5173
2026-02-09 20:31:47,107 - __main__ - INFO - Epoch 58, Batch 300, Loss: 13.5358
2026-02-09 20:31:47,445 - __main__ - INFO - Epoch 58: Train Loss: 12.9754, Val Loss: 15.5227
2026-02-09 20:31:47,563 - __main__ - INFO - Epoch 59, Batch 0, Loss: 12.0570
2026-02-09 20:31:47,835 - __main__ - INFO - Epoch 59, Batch 50, Loss: 11.3333
2026-02-09 20:31:48,058 - __main__ - INFO - Epoch 59, Batch 100, Loss: 13.7399
2026-02-09 20:31:48,295 - __main__ - INFO - Epoch 59, Batch 150, Loss: 12.2546
2026-02-09 20:31:48,516 - __main__ - INFO - Epoch 59, Batch 200, Loss: 13.1239
2026-02-09 20:31:48,737 - __main__ - INFO - Epoch 59, Batch 250, Loss: 13.1446
2026-02-09 20:31:48,947 - __main__ - INFO - Epoch 59, Batch 300, Loss: 11.3488
2026-02-09 20:31:49,276 - __main__ - INFO - Epoch 59: Train Loss: 12.9668, Val Loss: 15.5472
2026-02-09 20:31:49,405 - __main__ - INFO - Epoch 60, Batch 0, Loss: 13.3792
2026-02-09 20:31:49,628 - __main__ - INFO - Epoch 60, Batch 50, Loss: 15.0596
2026-02-09 20:31:49,879 - __main__ - INFO - Epoch 60, Batch 100, Loss: 12.2510
2026-02-09 20:31:50,098 - __main__ - INFO - Epoch 60, Batch 150, Loss: 12.1007
2026-02-09 20:31:50,309 - __main__ - INFO - Epoch 60, Batch 200, Loss: 12.8691
2026-02-09 20:31:50,531 - __main__ - INFO - Epoch 60, Batch 250, Loss: 12.5076
2026-02-09 20:31:50,752 - __main__ - INFO - Epoch 60, Batch 300, Loss: 12.7719
2026-02-09 20:31:51,092 - __main__ - INFO - Epoch 60: Train Loss: 12.9702, Val Loss: 15.5722
2026-02-09 20:31:51,210 - __main__ - INFO - Epoch 61, Batch 0, Loss: 12.6801
2026-02-09 20:31:51,423 - __main__ - INFO - Epoch 61, Batch 50, Loss: 14.3519
2026-02-09 20:31:51,652 - __main__ - INFO - Epoch 61, Batch 100, Loss: 14.5769
2026-02-09 20:31:51,908 - __main__ - INFO - Epoch 61, Batch 150, Loss: 13.4431
2026-02-09 20:31:52,120 - __main__ - INFO - Epoch 61, Batch 200, Loss: 11.1215
2026-02-09 20:31:52,325 - __main__ - INFO - Epoch 61, Batch 250, Loss: 13.4801
2026-02-09 20:31:52,541 - __main__ - INFO - Epoch 61, Batch 300, Loss: 12.9209
2026-02-09 20:31:52,897 - __main__ - INFO - Epoch 61: Train Loss: 12.9612, Val Loss: 15.6399
2026-02-09 20:31:53,017 - __main__ - INFO - Epoch 62, Batch 0, Loss: 13.5153
2026-02-09 20:31:53,242 - __main__ - INFO - Epoch 62, Batch 50, Loss: 13.8684
2026-02-09 20:31:53,452 - __main__ - INFO - Epoch 62, Batch 100, Loss: 12.0307
2026-02-09 20:31:53,681 - __main__ - INFO - Epoch 62, Batch 150, Loss: 12.1656
2026-02-09 20:31:53,936 - __main__ - INFO - Epoch 62, Batch 200, Loss: 13.7720
2026-02-09 20:31:54,139 - __main__ - INFO - Epoch 62, Batch 250, Loss: 11.3175
2026-02-09 20:31:54,345 - __main__ - INFO - Epoch 62, Batch 300, Loss: 12.7335
2026-02-09 20:31:54,677 - __main__ - INFO - Epoch 62: Train Loss: 12.9615, Val Loss: 15.7887
2026-02-09 20:31:54,806 - __main__ - INFO - Epoch 63, Batch 0, Loss: 15.3368
2026-02-09 20:31:55,023 - __main__ - INFO - Epoch 63, Batch 50, Loss: 12.2464
2026-02-09 20:31:55,229 - __main__ - INFO - Epoch 63, Batch 100, Loss: 12.8356
2026-02-09 20:31:55,456 - __main__ - INFO - Epoch 63, Batch 150, Loss: 12.5021
2026-02-09 20:31:55,679 - __main__ - INFO - Epoch 63, Batch 200, Loss: 12.0996
2026-02-09 20:31:55,926 - __main__ - INFO - Epoch 63, Batch 250, Loss: 12.5242
2026-02-09 20:31:56,142 - __main__ - INFO - Epoch 63, Batch 300, Loss: 11.6354
2026-02-09 20:31:56,473 - __main__ - INFO - Epoch 63: Train Loss: 12.9723, Val Loss: 15.5367
2026-02-09 20:31:56,600 - __main__ - INFO - Epoch 64, Batch 0, Loss: 11.6586
2026-02-09 20:31:56,826 - __main__ - INFO - Epoch 64, Batch 50, Loss: 10.8731
2026-02-09 20:31:57,035 - __main__ - INFO - Epoch 64, Batch 100, Loss: 14.0322
2026-02-09 20:31:57,261 - __main__ - INFO - Epoch 64, Batch 150, Loss: 12.4301
2026-02-09 20:31:57,481 - __main__ - INFO - Epoch 64, Batch 200, Loss: 12.9835
2026-02-09 20:31:57,703 - __main__ - INFO - Epoch 64, Batch 250, Loss: 11.7915
2026-02-09 20:31:57,953 - __main__ - INFO - Epoch 64, Batch 300, Loss: 12.2210
2026-02-09 20:31:58,283 - __main__ - INFO - Epoch 64: Train Loss: 12.9573, Val Loss: 15.4371
2026-02-09 20:31:58,398 - __main__ - INFO - Epoch 65, Batch 0, Loss: 13.2070
2026-02-09 20:31:58,624 - __main__ - INFO - Epoch 65, Batch 50, Loss: 13.0868
2026-02-09 20:31:58,860 - __main__ - INFO - Epoch 65, Batch 100, Loss: 13.1862
2026-02-09 20:31:59,074 - __main__ - INFO - Epoch 65, Batch 150, Loss: 14.2518
2026-02-09 20:31:59,280 - __main__ - INFO - Epoch 65, Batch 200, Loss: 12.8250
2026-02-09 20:31:59,512 - __main__ - INFO - Epoch 65, Batch 250, Loss: 12.1689
2026-02-09 20:31:59,725 - __main__ - INFO - Epoch 65, Batch 300, Loss: 13.4865
2026-02-09 20:32:00,063 - __main__ - INFO - Epoch 65: Train Loss: 12.9748, Val Loss: 15.5181
2026-02-09 20:32:00,179 - __main__ - INFO - Epoch 66, Batch 0, Loss: 12.5135
2026-02-09 20:32:00,402 - __main__ - INFO - Epoch 66, Batch 50, Loss: 14.5702
2026-02-09 20:32:00,661 - __main__ - INFO - Epoch 66, Batch 100, Loss: 13.8043
2026-02-09 20:32:00,917 - __main__ - INFO - Epoch 66, Batch 150, Loss: 11.7490
2026-02-09 20:32:01,129 - __main__ - INFO - Epoch 66, Batch 200, Loss: 13.3696
2026-02-09 20:32:01,336 - __main__ - INFO - Epoch 66, Batch 250, Loss: 13.5631
2026-02-09 20:32:01,544 - __main__ - INFO - Epoch 66, Batch 300, Loss: 14.0348
2026-02-09 20:32:01,925 - __main__ - INFO - Epoch 66: Train Loss: 12.9772, Val Loss: 15.7578
2026-02-09 20:32:02,038 - __main__ - INFO - Epoch 67, Batch 0, Loss: 13.1161
2026-02-09 20:32:02,261 - __main__ - INFO - Epoch 67, Batch 50, Loss: 13.3376
2026-02-09 20:32:02,469 - __main__ - INFO - Epoch 67, Batch 100, Loss: 12.8571
2026-02-09 20:32:02,697 - __main__ - INFO - Epoch 67, Batch 150, Loss: 13.7521
2026-02-09 20:32:02,919 - __main__ - INFO - Epoch 67, Batch 200, Loss: 12.2451
2026-02-09 20:32:03,126 - __main__ - INFO - Epoch 67, Batch 250, Loss: 12.7939
2026-02-09 20:32:03,331 - __main__ - INFO - Epoch 67, Batch 300, Loss: 11.6506
2026-02-09 20:32:03,675 - __main__ - INFO - Epoch 67: Train Loss: 12.9514, Val Loss: 15.6503
2026-02-09 20:32:03,829 - __main__ - INFO - Epoch 68, Batch 0, Loss: 12.2926
2026-02-09 20:32:04,033 - __main__ - INFO - Epoch 68, Batch 50, Loss: 12.0852
2026-02-09 20:32:04,240 - __main__ - INFO - Epoch 68, Batch 100, Loss: 12.1609
2026-02-09 20:32:04,458 - __main__ - INFO - Epoch 68, Batch 150, Loss: 13.2691
2026-02-09 20:32:04,671 - __main__ - INFO - Epoch 68, Batch 200, Loss: 12.8574
2026-02-09 20:32:04,898 - __main__ - INFO - Epoch 68, Batch 250, Loss: 13.2990
2026-02-09 20:32:05,112 - __main__ - INFO - Epoch 68, Batch 300, Loss: 13.0946
2026-02-09 20:32:05,434 - __main__ - INFO - Epoch 68: Train Loss: 12.9635, Val Loss: 15.8653
2026-02-09 20:32:05,558 - __main__ - INFO - Epoch 69, Batch 0, Loss: 10.9878
2026-02-09 20:32:05,791 - __main__ - INFO - Epoch 69, Batch 50, Loss: 14.2023
2026-02-09 20:32:06,014 - __main__ - INFO - Epoch 69, Batch 100, Loss: 12.5120
2026-02-09 20:32:06,236 - __main__ - INFO - Epoch 69, Batch 150, Loss: 14.5469
2026-02-09 20:32:06,452 - __main__ - INFO - Epoch 69, Batch 200, Loss: 12.4472
2026-02-09 20:32:06,661 - __main__ - INFO - Epoch 69, Batch 250, Loss: 14.4829
2026-02-09 20:32:06,887 - __main__ - INFO - Epoch 69, Batch 300, Loss: 13.4137
2026-02-09 20:32:07,214 - __main__ - INFO - Epoch 69: Train Loss: 12.9720, Val Loss: 15.4731
2026-02-09 20:32:07,332 - __main__ - INFO - Epoch 70, Batch 0, Loss: 11.4257
2026-02-09 20:32:07,536 - __main__ - INFO - Epoch 70, Batch 50, Loss: 12.2582
2026-02-09 20:32:07,769 - __main__ - INFO - Epoch 70, Batch 100, Loss: 13.5055
2026-02-09 20:32:08,019 - __main__ - INFO - Epoch 70, Batch 150, Loss: 13.0645
2026-02-09 20:32:08,235 - __main__ - INFO - Epoch 70, Batch 200, Loss: 13.3547
2026-02-09 20:32:08,435 - __main__ - INFO - Epoch 70, Batch 250, Loss: 13.5679
2026-02-09 20:32:08,685 - __main__ - INFO - Epoch 70, Batch 300, Loss: 14.0027
2026-02-09 20:32:09,026 - __main__ - INFO - Epoch 70: Train Loss: 12.9630, Val Loss: 15.6236
2026-02-09 20:32:09,147 - __main__ - INFO - Epoch 71, Batch 0, Loss: 12.8783
2026-02-09 20:32:09,349 - __main__ - INFO - Epoch 71, Batch 50, Loss: 13.8303
2026-02-09 20:32:09,549 - __main__ - INFO - Epoch 71, Batch 100, Loss: 11.2304
2026-02-09 20:32:09,825 - __main__ - INFO - Epoch 71, Batch 150, Loss: 12.3852
2026-02-09 20:32:10,034 - __main__ - INFO - Epoch 71, Batch 200, Loss: 13.3707
2026-02-09 20:32:10,255 - __main__ - INFO - Epoch 71, Batch 250, Loss: 12.6533
2026-02-09 20:32:10,467 - __main__ - INFO - Epoch 71, Batch 300, Loss: 14.2678
2026-02-09 20:32:10,825 - __main__ - INFO - Epoch 71: Train Loss: 12.9624, Val Loss: 15.4829
2026-02-09 20:32:10,942 - __main__ - INFO - Epoch 72, Batch 0, Loss: 13.3894
2026-02-09 20:32:11,187 - __main__ - INFO - Epoch 72, Batch 50, Loss: 13.1469
2026-02-09 20:32:11,390 - __main__ - INFO - Epoch 72, Batch 100, Loss: 13.4068
2026-02-09 20:32:11,621 - __main__ - INFO - Epoch 72, Batch 150, Loss: 12.0255
2026-02-09 20:32:11,875 - __main__ - INFO - Epoch 72, Batch 200, Loss: 12.4514
2026-02-09 20:32:12,090 - __main__ - INFO - Epoch 72, Batch 250, Loss: 13.1795
2026-02-09 20:32:12,302 - __main__ - INFO - Epoch 72, Batch 300, Loss: 12.6127
2026-02-09 20:32:12,657 - __main__ - INFO - Epoch 72: Train Loss: 12.9510, Val Loss: 15.4262
2026-02-09 20:32:12,785 - __main__ - INFO - Epoch 73, Batch 0, Loss: 12.5508
2026-02-09 20:32:13,019 - __main__ - INFO - Epoch 73, Batch 50, Loss: 13.1989
2026-02-09 20:32:13,231 - __main__ - INFO - Epoch 73, Batch 100, Loss: 12.6511
2026-02-09 20:32:13,453 - __main__ - INFO - Epoch 73, Batch 150, Loss: 13.8950
2026-02-09 20:32:13,679 - __main__ - INFO - Epoch 73, Batch 200, Loss: 11.0333
2026-02-09 20:32:13,927 - __main__ - INFO - Epoch 73, Batch 250, Loss: 13.5965
2026-02-09 20:32:14,130 - __main__ - INFO - Epoch 73, Batch 300, Loss: 13.1804
2026-02-09 20:32:14,456 - __main__ - INFO - Epoch 73: Train Loss: 12.9458, Val Loss: 15.5676
2026-02-09 20:32:14,574 - __main__ - INFO - Epoch 74, Batch 0, Loss: 12.6332
2026-02-09 20:32:14,829 - __main__ - INFO - Epoch 74, Batch 50, Loss: 13.4356
2026-02-09 20:32:15,037 - __main__ - INFO - Epoch 74, Batch 100, Loss: 12.0625
2026-02-09 20:32:15,258 - __main__ - INFO - Epoch 74, Batch 150, Loss: 13.7392
2026-02-09 20:32:15,466 - __main__ - INFO - Epoch 74, Batch 200, Loss: 12.9651
2026-02-09 20:32:15,675 - __main__ - INFO - Epoch 74, Batch 250, Loss: 10.2863
2026-02-09 20:32:15,929 - __main__ - INFO - Epoch 74, Batch 300, Loss: 14.2087
2026-02-09 20:32:16,258 - __main__ - INFO - Epoch 74: Train Loss: 12.9322, Val Loss: 15.4822
2026-02-09 20:32:16,384 - __main__ - INFO - Epoch 75, Batch 0, Loss: 12.1556
2026-02-09 20:32:16,593 - __main__ - INFO - Epoch 75, Batch 50, Loss: 12.0862
2026-02-09 20:32:16,817 - __main__ - INFO - Epoch 75, Batch 100, Loss: 12.4650
2026-02-09 20:32:17,043 - __main__ - INFO - Epoch 75, Batch 150, Loss: 13.0569
2026-02-09 20:32:17,246 - __main__ - INFO - Epoch 75, Batch 200, Loss: 10.9926
2026-02-09 20:32:17,463 - __main__ - INFO - Epoch 75, Batch 250, Loss: 13.4295
2026-02-09 20:32:17,683 - __main__ - INFO - Epoch 75, Batch 300, Loss: 13.7802
2026-02-09 20:32:18,048 - __main__ - INFO - Epoch 75: Train Loss: 12.9382, Val Loss: 15.6323
2026-02-09 20:32:18,174 - __main__ - INFO - Epoch 76, Batch 0, Loss: 13.1842
2026-02-09 20:32:18,389 - __main__ - INFO - Epoch 76, Batch 50, Loss: 13.1653
2026-02-09 20:32:18,600 - __main__ - INFO - Epoch 76, Batch 100, Loss: 12.8324
2026-02-09 20:32:18,836 - __main__ - INFO - Epoch 76, Batch 150, Loss: 14.2960
2026-02-09 20:32:19,045 - __main__ - INFO - Epoch 76, Batch 200, Loss: 13.7117
2026-02-09 20:32:19,246 - __main__ - INFO - Epoch 76, Batch 250, Loss: 12.2904
2026-02-09 20:32:19,460 - __main__ - INFO - Epoch 76, Batch 300, Loss: 13.3960
2026-02-09 20:32:19,842 - __main__ - INFO - Epoch 76: Train Loss: 12.9865, Val Loss: 15.4343
2026-02-09 20:32:19,965 - __main__ - INFO - Epoch 77, Batch 0, Loss: 12.6050
2026-02-09 20:32:20,175 - __main__ - INFO - Epoch 77, Batch 50, Loss: 12.4765
2026-02-09 20:32:20,387 - __main__ - INFO - Epoch 77, Batch 100, Loss: 14.9630
2026-02-09 20:32:20,633 - __main__ - INFO - Epoch 77, Batch 150, Loss: 12.8693
2026-02-09 20:32:20,866 - __main__ - INFO - Epoch 77, Batch 200, Loss: 14.2123
2026-02-09 20:32:21,078 - __main__ - INFO - Epoch 77, Batch 250, Loss: 13.3275
2026-02-09 20:32:21,278 - __main__ - INFO - Epoch 77, Batch 300, Loss: 13.0763
2026-02-09 20:32:21,605 - __main__ - INFO - Epoch 77: Train Loss: 12.9198, Val Loss: 15.4718
2026-02-09 20:32:21,721 - __main__ - INFO - Epoch 78, Batch 0, Loss: 12.4590
2026-02-09 20:32:21,971 - __main__ - INFO - Epoch 78, Batch 50, Loss: 13.2246
2026-02-09 20:32:22,227 - __main__ - INFO - Epoch 78, Batch 100, Loss: 12.8194
2026-02-09 20:32:22,454 - __main__ - INFO - Epoch 78, Batch 150, Loss: 11.4188
2026-02-09 20:32:22,690 - __main__ - INFO - Epoch 78, Batch 200, Loss: 14.2096
2026-02-09 20:32:22,931 - __main__ - INFO - Epoch 78, Batch 250, Loss: 13.4390
2026-02-09 20:32:23,146 - __main__ - INFO - Epoch 78, Batch 300, Loss: 13.9399
2026-02-09 20:32:23,500 - __main__ - INFO - Epoch 78: Train Loss: 12.9690, Val Loss: 15.6429
2026-02-09 20:32:23,634 - __main__ - INFO - Epoch 79, Batch 0, Loss: 13.3427
2026-02-09 20:32:23,886 - __main__ - INFO - Epoch 79, Batch 50, Loss: 14.2150
2026-02-09 20:32:24,104 - __main__ - INFO - Epoch 79, Batch 100, Loss: 12.5388
2026-02-09 20:32:24,326 - __main__ - INFO - Epoch 79, Batch 150, Loss: 14.1730
2026-02-09 20:32:24,532 - __main__ - INFO - Epoch 79, Batch 200, Loss: 13.0567
2026-02-09 20:32:24,750 - __main__ - INFO - Epoch 79, Batch 250, Loss: 13.1398
2026-02-09 20:32:24,971 - __main__ - INFO - Epoch 79, Batch 300, Loss: 14.0507
2026-02-09 20:32:25,321 - __main__ - INFO - Epoch 79: Train Loss: 12.9424, Val Loss: 15.4868
2026-02-09 20:32:25,440 - __main__ - INFO - Epoch 80, Batch 0, Loss: 11.5037
2026-02-09 20:32:25,667 - __main__ - INFO - Epoch 80, Batch 50, Loss: 12.0658
2026-02-09 20:32:25,923 - __main__ - INFO - Epoch 80, Batch 100, Loss: 12.1894
2026-02-09 20:32:26,139 - __main__ - INFO - Epoch 80, Batch 150, Loss: 10.7651
2026-02-09 20:32:26,362 - __main__ - INFO - Epoch 80, Batch 200, Loss: 11.0908
2026-02-09 20:32:26,577 - __main__ - INFO - Epoch 80, Batch 250, Loss: 14.0484
2026-02-09 20:32:26,805 - __main__ - INFO - Epoch 80, Batch 300, Loss: 13.6980
2026-02-09 20:32:27,162 - __main__ - INFO - Epoch 80: Train Loss: 12.9463, Val Loss: 15.4648
2026-02-09 20:32:27,290 - __main__ - INFO - Epoch 81, Batch 0, Loss: 15.0531
2026-02-09 20:32:27,515 - __main__ - INFO - Epoch 81, Batch 50, Loss: 12.6317
2026-02-09 20:32:27,754 - __main__ - INFO - Epoch 81, Batch 100, Loss: 12.9623
2026-02-09 20:32:28,015 - __main__ - INFO - Epoch 81, Batch 150, Loss: 14.4525
2026-02-09 20:32:28,225 - __main__ - INFO - Epoch 81, Batch 200, Loss: 12.8793
2026-02-09 20:32:28,442 - __main__ - INFO - Epoch 81, Batch 250, Loss: 13.1223
2026-02-09 20:32:28,668 - __main__ - INFO - Epoch 81, Batch 300, Loss: 11.9760
2026-02-09 20:32:29,024 - __main__ - INFO - Epoch 81: Train Loss: 12.9474, Val Loss: 15.5184
2026-02-09 20:32:29,135 - __main__ - INFO - Epoch 82, Batch 0, Loss: 12.8676
2026-02-09 20:32:29,377 - __main__ - INFO - Epoch 82, Batch 50, Loss: 12.0286
2026-02-09 20:32:29,583 - __main__ - INFO - Epoch 82, Batch 100, Loss: 13.7788
2026-02-09 20:32:29,844 - __main__ - INFO - Epoch 82, Batch 150, Loss: 11.6911
2026-02-09 20:32:30,052 - __main__ - INFO - Epoch 82, Batch 200, Loss: 12.7097
2026-02-09 20:32:30,265 - __main__ - INFO - Epoch 82, Batch 250, Loss: 11.6545
2026-02-09 20:32:30,474 - __main__ - INFO - Epoch 82, Batch 300, Loss: 12.4017
2026-02-09 20:32:30,827 - __main__ - INFO - Epoch 82: Train Loss: 12.9388, Val Loss: 15.4709
2026-02-09 20:32:30,948 - __main__ - INFO - Epoch 83, Batch 0, Loss: 14.3331
2026-02-09 20:32:31,154 - __main__ - INFO - Epoch 83, Batch 50, Loss: 11.2724
2026-02-09 20:32:31,366 - __main__ - INFO - Epoch 83, Batch 100, Loss: 14.0722
2026-02-09 20:32:31,580 - __main__ - INFO - Epoch 83, Batch 150, Loss: 10.7139
2026-02-09 20:32:31,831 - __main__ - INFO - Epoch 83, Batch 200, Loss: 12.2448
2026-02-09 20:32:32,042 - __main__ - INFO - Epoch 83, Batch 250, Loss: 11.5157
2026-02-09 20:32:32,248 - __main__ - INFO - Epoch 83, Batch 300, Loss: 13.7787
2026-02-09 20:32:32,583 - __main__ - INFO - Epoch 83: Train Loss: 12.9320, Val Loss: 15.5270
2026-02-09 20:32:32,697 - __main__ - INFO - Epoch 84, Batch 0, Loss: 14.3868
2026-02-09 20:32:32,937 - __main__ - INFO - Epoch 84, Batch 50, Loss: 14.4824
2026-02-09 20:32:33,152 - __main__ - INFO - Epoch 84, Batch 100, Loss: 12.5426
2026-02-09 20:32:33,371 - __main__ - INFO - Epoch 84, Batch 150, Loss: 11.7909
2026-02-09 20:32:33,597 - __main__ - INFO - Epoch 84, Batch 200, Loss: 12.6473
2026-02-09 20:32:33,859 - __main__ - INFO - Epoch 84, Batch 250, Loss: 12.4246
2026-02-09 20:32:34,071 - __main__ - INFO - Epoch 84, Batch 300, Loss: 11.6610
2026-02-09 20:32:34,397 - __main__ - INFO - Epoch 84: Train Loss: 12.9388, Val Loss: 15.5553
2026-02-09 20:32:34,515 - __main__ - INFO - Epoch 85, Batch 0, Loss: 12.9203
2026-02-09 20:32:34,743 - __main__ - INFO - Epoch 85, Batch 50, Loss: 12.3610
2026-02-09 20:32:34,971 - __main__ - INFO - Epoch 85, Batch 100, Loss: 14.5037
2026-02-09 20:32:35,191 - __main__ - INFO - Epoch 85, Batch 150, Loss: 12.5151
2026-02-09 20:32:35,407 - __main__ - INFO - Epoch 85, Batch 200, Loss: 12.9856
2026-02-09 20:32:35,620 - __main__ - INFO - Epoch 85, Batch 250, Loss: 11.6420
2026-02-09 20:32:35,877 - __main__ - INFO - Epoch 85, Batch 300, Loss: 13.0309
2026-02-09 20:32:36,225 - __main__ - INFO - Epoch 85: Train Loss: 12.9411, Val Loss: 15.4567
2026-02-09 20:32:36,320 - __main__ - INFO - Epoch 86, Batch 0, Loss: 13.2723
2026-02-09 20:32:36,560 - __main__ - INFO - Epoch 86, Batch 50, Loss: 12.5995
2026-02-09 20:32:36,781 - __main__ - INFO - Epoch 86, Batch 100, Loss: 13.5360
2026-02-09 20:32:37,004 - __main__ - INFO - Epoch 86, Batch 150, Loss: 11.0229
2026-02-09 20:32:37,238 - __main__ - INFO - Epoch 86, Batch 200, Loss: 12.7440
2026-02-09 20:32:37,444 - __main__ - INFO - Epoch 86, Batch 250, Loss: 12.8636
2026-02-09 20:32:37,657 - __main__ - INFO - Epoch 86, Batch 300, Loss: 12.5427
2026-02-09 20:32:38,020 - __main__ - INFO - Epoch 86: Train Loss: 12.9331, Val Loss: 15.4196
2026-02-09 20:32:38,139 - __main__ - INFO - Epoch 87, Batch 0, Loss: 13.2368
2026-02-09 20:32:38,342 - __main__ - INFO - Epoch 87, Batch 50, Loss: 12.5994
2026-02-09 20:32:38,548 - __main__ - INFO - Epoch 87, Batch 100, Loss: 12.6731
2026-02-09 20:32:38,783 - __main__ - INFO - Epoch 87, Batch 150, Loss: 12.4764
2026-02-09 20:32:38,996 - __main__ - INFO - Epoch 87, Batch 200, Loss: 12.9672
2026-02-09 20:32:39,213 - __main__ - INFO - Epoch 87, Batch 250, Loss: 11.9529
2026-02-09 20:32:39,426 - __main__ - INFO - Epoch 87, Batch 300, Loss: 13.1659
2026-02-09 20:32:39,791 - __main__ - INFO - Epoch 87: Train Loss: 12.9334, Val Loss: 15.4455
2026-02-09 20:32:39,898 - __main__ - INFO - Epoch 88, Batch 0, Loss: 12.4773
2026-02-09 20:32:40,133 - __main__ - INFO - Epoch 88, Batch 50, Loss: 14.3629
2026-02-09 20:32:40,338 - __main__ - INFO - Epoch 88, Batch 100, Loss: 13.3376
2026-02-09 20:32:40,564 - __main__ - INFO - Epoch 88, Batch 150, Loss: 12.4481
2026-02-09 20:32:40,795 - __main__ - INFO - Epoch 88, Batch 200, Loss: 14.7685
2026-02-09 20:32:41,009 - __main__ - INFO - Epoch 88, Batch 250, Loss: 13.3438
2026-02-09 20:32:41,215 - __main__ - INFO - Epoch 88, Batch 300, Loss: 14.5840
2026-02-09 20:32:41,542 - __main__ - INFO - Epoch 88: Train Loss: 12.9297, Val Loss: 15.4111
2026-02-09 20:32:41,663 - __main__ - INFO - Epoch 89, Batch 0, Loss: 13.3524
2026-02-09 20:32:41,911 - __main__ - INFO - Epoch 89, Batch 50, Loss: 12.6121
2026-02-09 20:32:42,136 - __main__ - INFO - Epoch 89, Batch 100, Loss: 12.4952
2026-02-09 20:32:42,377 - __main__ - INFO - Epoch 89, Batch 150, Loss: 11.9315
2026-02-09 20:32:42,596 - __main__ - INFO - Epoch 89, Batch 200, Loss: 12.9230
2026-02-09 20:32:42,821 - __main__ - INFO - Epoch 89, Batch 250, Loss: 13.1187
2026-02-09 20:32:43,039 - __main__ - INFO - Epoch 89, Batch 300, Loss: 12.2443
2026-02-09 20:32:43,375 - __main__ - INFO - Epoch 89: Train Loss: 12.9406, Val Loss: 15.3757
2026-02-09 20:32:43,494 - __main__ - INFO - Epoch 90, Batch 0, Loss: 13.2585
2026-02-09 20:32:43,712 - __main__ - INFO - Epoch 90, Batch 50, Loss: 12.0891
2026-02-09 20:32:43,966 - __main__ - INFO - Epoch 90, Batch 100, Loss: 12.6579
2026-02-09 20:32:44,188 - __main__ - INFO - Epoch 90, Batch 150, Loss: 11.1596
2026-02-09 20:32:44,397 - __main__ - INFO - Epoch 90, Batch 200, Loss: 12.5339
2026-02-09 20:32:44,603 - __main__ - INFO - Epoch 90, Batch 250, Loss: 11.6082
2026-02-09 20:32:44,830 - __main__ - INFO - Epoch 90, Batch 300, Loss: 14.9154
2026-02-09 20:32:45,171 - __main__ - INFO - Epoch 90: Train Loss: 12.9284, Val Loss: 15.3897
2026-02-09 20:32:45,288 - __main__ - INFO - Epoch 91, Batch 0, Loss: 12.2492
2026-02-09 20:32:45,514 - __main__ - INFO - Epoch 91, Batch 50, Loss: 13.3014
2026-02-09 20:32:45,733 - __main__ - INFO - Epoch 91, Batch 100, Loss: 12.7683
2026-02-09 20:32:45,990 - __main__ - INFO - Epoch 91, Batch 150, Loss: 13.5457
2026-02-09 20:32:46,205 - __main__ - INFO - Epoch 91, Batch 200, Loss: 10.5623
2026-02-09 20:32:46,416 - __main__ - INFO - Epoch 91, Batch 250, Loss: 15.1363
2026-02-09 20:32:46,632 - __main__ - INFO - Epoch 91, Batch 300, Loss: 12.3515
2026-02-09 20:32:46,985 - __main__ - INFO - Epoch 91: Train Loss: 12.9400, Val Loss: 15.4300
2026-02-09 20:32:47,104 - __main__ - INFO - Epoch 92, Batch 0, Loss: 10.4886
2026-02-09 20:32:47,335 - __main__ - INFO - Epoch 92, Batch 50, Loss: 11.2089
2026-02-09 20:32:47,547 - __main__ - INFO - Epoch 92, Batch 100, Loss: 15.3885
2026-02-09 20:32:47,769 - __main__ - INFO - Epoch 92, Batch 150, Loss: 11.6714
2026-02-09 20:32:48,026 - __main__ - INFO - Epoch 92, Batch 200, Loss: 13.5650
2026-02-09 20:32:48,232 - __main__ - INFO - Epoch 92, Batch 250, Loss: 12.3074
2026-02-09 20:32:48,440 - __main__ - INFO - Epoch 92, Batch 300, Loss: 11.1280
2026-02-09 20:32:48,775 - __main__ - INFO - Epoch 92: Train Loss: 12.9251, Val Loss: 15.4039
2026-02-09 20:32:48,902 - __main__ - INFO - Epoch 93, Batch 0, Loss: 14.0082
2026-02-09 20:32:49,109 - __main__ - INFO - Epoch 93, Batch 50, Loss: 11.7576
2026-02-09 20:32:49,318 - __main__ - INFO - Epoch 93, Batch 100, Loss: 13.4341
2026-02-09 20:32:49,541 - __main__ - INFO - Epoch 93, Batch 150, Loss: 12.3170
2026-02-09 20:32:49,759 - __main__ - INFO - Epoch 93, Batch 200, Loss: 11.6391
2026-02-09 20:32:50,045 - __main__ - INFO - Epoch 93, Batch 250, Loss: 11.7827
2026-02-09 20:32:50,288 - __main__ - INFO - Epoch 93, Batch 300, Loss: 12.7459
2026-02-09 20:32:50,628 - __main__ - INFO - Epoch 93: Train Loss: 12.9318, Val Loss: 15.4002
2026-02-09 20:32:50,749 - __main__ - INFO - Epoch 94, Batch 0, Loss: 11.3147
2026-02-09 20:32:50,991 - __main__ - INFO - Epoch 94, Batch 50, Loss: 12.8432
2026-02-09 20:32:51,198 - __main__ - INFO - Epoch 94, Batch 100, Loss: 11.5854
2026-02-09 20:32:51,413 - __main__ - INFO - Epoch 94, Batch 150, Loss: 13.7006
2026-02-09 20:32:51,627 - __main__ - INFO - Epoch 94, Batch 200, Loss: 14.3545
2026-02-09 20:32:51,872 - __main__ - INFO - Epoch 94, Batch 250, Loss: 12.5020
2026-02-09 20:32:52,080 - __main__ - INFO - Epoch 94, Batch 300, Loss: 11.7673
2026-02-09 20:32:52,407 - __main__ - INFO - Epoch 94: Train Loss: 12.9474, Val Loss: 15.3898
2026-02-09 20:32:52,525 - __main__ - INFO - Epoch 95, Batch 0, Loss: 11.7465
2026-02-09 20:32:52,746 - __main__ - INFO - Epoch 95, Batch 50, Loss: 11.7955
2026-02-09 20:32:52,973 - __main__ - INFO - Epoch 95, Batch 100, Loss: 12.9817
2026-02-09 20:32:53,206 - __main__ - INFO - Epoch 95, Batch 150, Loss: 12.2502
2026-02-09 20:32:53,408 - __main__ - INFO - Epoch 95, Batch 200, Loss: 12.9734
2026-02-09 20:32:53,612 - __main__ - INFO - Epoch 95, Batch 250, Loss: 12.8613
2026-02-09 20:32:53,850 - __main__ - INFO - Epoch 95, Batch 300, Loss: 14.6244
2026-02-09 20:32:54,192 - __main__ - INFO - Epoch 95: Train Loss: 12.9406, Val Loss: 15.3858
2026-02-09 20:32:54,309 - __main__ - INFO - Epoch 96, Batch 0, Loss: 13.1005
2026-02-09 20:32:54,520 - __main__ - INFO - Epoch 96, Batch 50, Loss: 13.3484
2026-02-09 20:32:54,739 - __main__ - INFO - Epoch 96, Batch 100, Loss: 11.0352
2026-02-09 20:32:54,977 - __main__ - INFO - Epoch 96, Batch 150, Loss: 13.7053
2026-02-09 20:32:55,195 - __main__ - INFO - Epoch 96, Batch 200, Loss: 13.7681
2026-02-09 20:32:55,401 - __main__ - INFO - Epoch 96, Batch 250, Loss: 13.2809
2026-02-09 20:32:55,606 - __main__ - INFO - Epoch 96, Batch 300, Loss: 12.2760
2026-02-09 20:32:55,995 - __main__ - INFO - Epoch 96: Train Loss: 12.9447, Val Loss: 15.3995
2026-02-09 20:32:56,130 - __main__ - INFO - Epoch 97, Batch 0, Loss: 12.5598
2026-02-09 20:32:56,337 - __main__ - INFO - Epoch 97, Batch 50, Loss: 12.8003
2026-02-09 20:32:56,545 - __main__ - INFO - Epoch 97, Batch 100, Loss: 12.3847
2026-02-09 20:32:56,775 - __main__ - INFO - Epoch 97, Batch 150, Loss: 14.6691
2026-02-09 20:32:56,999 - __main__ - INFO - Epoch 97, Batch 200, Loss: 12.8973
2026-02-09 20:32:57,227 - __main__ - INFO - Epoch 97, Batch 250, Loss: 13.2977
2026-02-09 20:32:57,432 - __main__ - INFO - Epoch 97, Batch 300, Loss: 12.1378
2026-02-09 20:32:57,767 - __main__ - INFO - Epoch 97: Train Loss: 12.9444, Val Loss: 15.3915
2026-02-09 20:32:57,877 - __main__ - INFO - Epoch 98, Batch 0, Loss: 12.7201
2026-02-09 20:32:58,111 - __main__ - INFO - Epoch 98, Batch 50, Loss: 14.3865
2026-02-09 20:32:58,327 - __main__ - INFO - Epoch 98, Batch 100, Loss: 12.8470
2026-02-09 20:32:58,550 - __main__ - INFO - Epoch 98, Batch 150, Loss: 11.3777
2026-02-09 20:32:58,785 - __main__ - INFO - Epoch 98, Batch 200, Loss: 12.8655
2026-02-09 20:32:59,012 - __main__ - INFO - Epoch 98, Batch 250, Loss: 13.3246
2026-02-09 20:32:59,223 - __main__ - INFO - Epoch 98, Batch 300, Loss: 13.2171
2026-02-09 20:32:59,556 - __main__ - INFO - Epoch 98: Train Loss: 12.9340, Val Loss: 15.3924
2026-02-09 20:32:59,679 - __main__ - INFO - Epoch 99, Batch 0, Loss: 11.4804
2026-02-09 20:32:59,936 - __main__ - INFO - Epoch 99, Batch 50, Loss: 12.5307
2026-02-09 20:33:00,148 - __main__ - INFO - Epoch 99, Batch 100, Loss: 13.6120
2026-02-09 20:33:00,371 - __main__ - INFO - Epoch 99, Batch 150, Loss: 13.9219
2026-02-09 20:33:00,588 - __main__ - INFO - Epoch 99, Batch 200, Loss: 14.3657
2026-02-09 20:33:00,863 - __main__ - INFO - Epoch 99, Batch 250, Loss: 11.6965
2026-02-09 20:33:01,076 - __main__ - INFO - Epoch 99, Batch 300, Loss: 12.3855
2026-02-09 20:33:01,410 - __main__ - INFO - Epoch 99: Train Loss: 12.9349, Val Loss: 15.3907
2026-02-09 20:33:01,529 - __main__ - INFO - Epoch 100, Batch 0, Loss: 13.1282
2026-02-09 20:33:01,757 - __main__ - INFO - Epoch 100, Batch 50, Loss: 11.4709
2026-02-09 20:33:02,008 - __main__ - INFO - Epoch 100, Batch 100, Loss: 12.7880
2026-02-09 20:33:02,226 - __main__ - INFO - Epoch 100, Batch 150, Loss: 11.6697
2026-02-09 20:33:02,445 - __main__ - INFO - Epoch 100, Batch 200, Loss: 12.9412
2026-02-09 20:33:02,679 - __main__ - INFO - Epoch 100, Batch 250, Loss: 13.7678
2026-02-09 20:33:02,922 - __main__ - INFO - Epoch 100, Batch 300, Loss: 13.1864
2026-02-09 20:33:03,266 - __main__ - INFO - Epoch 100: Train Loss: 12.9133, Val Loss: 15.3904
2026-02-09 20:33:03,267 - __main__ - INFO - Training completed!
2026-02-09 20:33:03,278 - __main__ - INFO - Model saved to checkpoints/trained_model.pt
2026-02-09 20:33:03,278 - __main__ - INFO - Evaluating on test set...
2026-02-09 20:33:03,397 - __main__ - ERROR - Training failed with error: float division by zero
2026-02-09 20:33:03,398 - __main__ - ERROR - Traceback (most recent call last):
  File "/media/alireza/D29856C39856A62F/AI project/projects/hierarchical-demand-reconciliation-with-temporal-anomaly-feedback/hierarchical-demand-reconciliation-with-temporal-anomaly-feedback/scripts/train.py", line 778, in main
    avg_test_loss = test_loss / len(test_loader)
                    ~~~~~~~~~~^~~~~~~~~~~~~~~~~~
ZeroDivisionError: float division by zero

2026-02-09 20:38:06,108 - __main__ - INFO - Starting hierarchical demand reconciliation training
2026-02-09 20:38:06,108 - __main__ - INFO - Arguments: Namespace(data_path='data', config='hierarchical-demand-reconciliation-with-temporal-anomaly-feedback/configs/default.yaml', synthetic_data=False, no_download=False, epochs=100, batch_size=64, learning_rate=0.001, weight_decay=0.0001, sequence_length=28, prediction_length=28, hidden_size=256, num_layers=4, num_heads=8, dropout=0.1, output_dir='results', checkpoint_dir='checkpoints', resume_from=None, device='auto', num_workers=4, seed=42, log_level='INFO')
2026-02-09 20:38:06,108 - __main__ - INFO - Configuration file not found, using default configuration
2026-02-09 20:38:06,191 - __main__ - INFO - Using device: cuda
2026-02-09 20:38:06,191 - __main__ - INFO - Using synthetic data
2026-02-09 20:38:06,191 - __main__ - INFO - Generating synthetic data: 100 items, 365 days
2026-02-09 20:38:06,340 - __main__ - INFO - Generated synthetic data with 36500 records
2026-02-09 20:38:06,341 - __main__ - INFO - Preparing data with simple preprocessing...
2026-02-09 20:38:06,349 - __main__ - INFO - Data split - Train: 25500, Val: 7300, Test: 3700
2026-02-09 20:38:06,806 - __main__ - INFO - Model has 3197596 parameters
2026-02-09 20:38:07,166 - __main__ - INFO - Starting training for 100 epochs...
2026-02-09 20:38:07,451 - __main__ - INFO - Epoch 1, Batch 0, Loss: 126.0124
2026-02-09 20:38:07,665 - __main__ - INFO - Epoch 1, Batch 50, Loss: 13.1194
2026-02-09 20:38:07,855 - __main__ - INFO - Epoch 1, Batch 100, Loss: 13.7868
2026-02-09 20:38:08,050 - __main__ - INFO - Epoch 1, Batch 150, Loss: 15.5224
2026-02-09 20:38:08,281 - __main__ - INFO - Epoch 1, Batch 200, Loss: 14.6401
2026-02-09 20:38:08,475 - __main__ - INFO - Epoch 1, Batch 250, Loss: 10.9394
2026-02-09 20:38:08,667 - __main__ - INFO - Epoch 1, Batch 300, Loss: 15.3118
2026-02-09 20:38:09,011 - __main__ - INFO - Epoch 1: Train Loss: 18.0524, Val Loss: 17.1897
2026-02-09 20:38:09,012 - __main__ - INFO - New best validation loss: 17.1897
2026-02-09 20:38:09,142 - __main__ - INFO - Epoch 2, Batch 0, Loss: 14.9004
2026-02-09 20:38:09,342 - __main__ - INFO - Epoch 2, Batch 50, Loss: 13.7497
2026-02-09 20:38:09,541 - __main__ - INFO - Epoch 2, Batch 100, Loss: 13.8136
2026-02-09 20:38:09,735 - __main__ - INFO - Epoch 2, Batch 150, Loss: 11.2460
2026-02-09 20:38:09,934 - __main__ - INFO - Epoch 2, Batch 200, Loss: 12.1957
2026-02-09 20:38:10,134 - __main__ - INFO - Epoch 2, Batch 250, Loss: 12.9424
2026-02-09 20:38:10,365 - __main__ - INFO - Epoch 2, Batch 300, Loss: 14.7210
2026-02-09 20:38:10,699 - __main__ - INFO - Epoch 2: Train Loss: 13.2066, Val Loss: 15.3086
2026-02-09 20:38:10,699 - __main__ - INFO - New best validation loss: 15.3086
2026-02-09 20:38:10,829 - __main__ - INFO - Epoch 3, Batch 0, Loss: 13.6198
2026-02-09 20:38:11,022 - __main__ - INFO - Epoch 3, Batch 50, Loss: 13.4812
2026-02-09 20:38:11,221 - __main__ - INFO - Epoch 3, Batch 100, Loss: 13.9574
2026-02-09 20:38:11,417 - __main__ - INFO - Epoch 3, Batch 150, Loss: 13.3469
2026-02-09 20:38:11,613 - __main__ - INFO - Epoch 3, Batch 200, Loss: 11.8631
2026-02-09 20:38:11,807 - __main__ - INFO - Epoch 3, Batch 250, Loss: 14.1771
2026-02-09 20:38:12,010 - __main__ - INFO - Epoch 3, Batch 300, Loss: 12.6474
2026-02-09 20:38:12,367 - __main__ - INFO - Epoch 3: Train Loss: 13.1349, Val Loss: 15.5191
2026-02-09 20:38:12,492 - __main__ - INFO - Epoch 4, Batch 0, Loss: 11.5186
2026-02-09 20:38:12,691 - __main__ - INFO - Epoch 4, Batch 50, Loss: 14.5350
2026-02-09 20:38:12,882 - __main__ - INFO - Epoch 4, Batch 100, Loss: 13.0830
2026-02-09 20:38:13,075 - __main__ - INFO - Epoch 4, Batch 150, Loss: 12.3428
2026-02-09 20:38:13,292 - __main__ - INFO - Epoch 4, Batch 200, Loss: 14.8034
2026-02-09 20:38:13,486 - __main__ - INFO - Epoch 4, Batch 250, Loss: 13.1363
2026-02-09 20:38:13,683 - __main__ - INFO - Epoch 4, Batch 300, Loss: 13.5016
2026-02-09 20:38:14,040 - __main__ - INFO - Epoch 4: Train Loss: 13.0884, Val Loss: 15.8771
2026-02-09 20:38:14,175 - __main__ - INFO - Epoch 5, Batch 0, Loss: 16.0576
2026-02-09 20:38:14,401 - __main__ - INFO - Epoch 5, Batch 50, Loss: 13.0715
2026-02-09 20:38:14,588 - __main__ - INFO - Epoch 5, Batch 100, Loss: 12.6684
2026-02-09 20:38:14,781 - __main__ - INFO - Epoch 5, Batch 150, Loss: 12.8351
2026-02-09 20:38:14,980 - __main__ - INFO - Epoch 5, Batch 200, Loss: 13.4759
2026-02-09 20:38:15,188 - __main__ - INFO - Epoch 5, Batch 250, Loss: 13.0466
2026-02-09 20:38:15,383 - __main__ - INFO - Epoch 5, Batch 300, Loss: 14.7571
2026-02-09 20:38:15,719 - __main__ - INFO - Epoch 5: Train Loss: 13.0915, Val Loss: 15.4574
2026-02-09 20:38:15,847 - __main__ - INFO - Epoch 6, Batch 0, Loss: 13.4335
2026-02-09 20:38:16,056 - __main__ - INFO - Epoch 6, Batch 50, Loss: 14.0772
2026-02-09 20:38:16,281 - __main__ - INFO - Epoch 6, Batch 100, Loss: 11.7078
2026-02-09 20:38:16,476 - __main__ - INFO - Epoch 6, Batch 150, Loss: 13.2576
2026-02-09 20:38:16,671 - __main__ - INFO - Epoch 6, Batch 200, Loss: 12.7263
2026-02-09 20:38:16,860 - __main__ - INFO - Epoch 6, Batch 250, Loss: 13.4626
2026-02-09 20:38:17,054 - __main__ - INFO - Epoch 6, Batch 300, Loss: 14.4801
2026-02-09 20:38:17,402 - __main__ - INFO - Epoch 6: Train Loss: 13.0766, Val Loss: 15.6400
2026-02-09 20:38:17,532 - __main__ - INFO - Epoch 7, Batch 0, Loss: 14.3549
2026-02-09 20:38:17,732 - __main__ - INFO - Epoch 7, Batch 50, Loss: 12.4234
2026-02-09 20:38:17,923 - __main__ - INFO - Epoch 7, Batch 100, Loss: 12.7857
2026-02-09 20:38:18,110 - __main__ - INFO - Epoch 7, Batch 150, Loss: 15.9146
2026-02-09 20:38:18,338 - __main__ - INFO - Epoch 7, Batch 200, Loss: 15.6115
2026-02-09 20:38:18,533 - __main__ - INFO - Epoch 7, Batch 250, Loss: 11.8901
2026-02-09 20:38:18,734 - __main__ - INFO - Epoch 7, Batch 300, Loss: 11.5825
2026-02-09 20:38:19,088 - __main__ - INFO - Epoch 7: Train Loss: 13.0692, Val Loss: 15.6386
2026-02-09 20:38:19,226 - __main__ - INFO - Epoch 8, Batch 0, Loss: 14.3384
2026-02-09 20:38:19,417 - __main__ - INFO - Epoch 8, Batch 50, Loss: 11.4083
2026-02-09 20:38:19,620 - __main__ - INFO - Epoch 8, Batch 100, Loss: 14.5733
2026-02-09 20:38:19,822 - __main__ - INFO - Epoch 8, Batch 150, Loss: 13.3135
2026-02-09 20:38:20,014 - __main__ - INFO - Epoch 8, Batch 200, Loss: 12.9706
2026-02-09 20:38:20,245 - __main__ - INFO - Epoch 8, Batch 250, Loss: 13.3688
2026-02-09 20:38:20,438 - __main__ - INFO - Epoch 8, Batch 300, Loss: 14.2943
2026-02-09 20:38:20,772 - __main__ - INFO - Epoch 8: Train Loss: 13.0322, Val Loss: 15.6669
2026-02-09 20:38:20,899 - __main__ - INFO - Epoch 9, Batch 0, Loss: 12.3675
2026-02-09 20:38:21,097 - __main__ - INFO - Epoch 9, Batch 50, Loss: 13.1432
2026-02-09 20:38:21,310 - __main__ - INFO - Epoch 9, Batch 100, Loss: 12.3565
2026-02-09 20:38:21,520 - __main__ - INFO - Epoch 9, Batch 150, Loss: 12.8332
2026-02-09 20:38:21,719 - __main__ - INFO - Epoch 9, Batch 200, Loss: 12.8327
2026-02-09 20:38:21,914 - __main__ - INFO - Epoch 9, Batch 250, Loss: 14.1901
2026-02-09 20:38:22,107 - __main__ - INFO - Epoch 9, Batch 300, Loss: 12.7301
2026-02-09 20:38:22,488 - __main__ - INFO - Epoch 9: Train Loss: 13.0430, Val Loss: 15.8081
2026-02-09 20:38:22,633 - __main__ - INFO - Epoch 10, Batch 0, Loss: 13.3931
2026-02-09 20:38:22,834 - __main__ - INFO - Epoch 10, Batch 50, Loss: 13.4121
2026-02-09 20:38:23,028 - __main__ - INFO - Epoch 10, Batch 100, Loss: 12.6559
2026-02-09 20:38:23,240 - __main__ - INFO - Epoch 10, Batch 150, Loss: 12.2954
2026-02-09 20:38:23,446 - __main__ - INFO - Epoch 10, Batch 200, Loss: 12.6175
2026-02-09 20:38:23,642 - __main__ - INFO - Epoch 10, Batch 250, Loss: 13.3965
2026-02-09 20:38:23,847 - __main__ - INFO - Epoch 10, Batch 300, Loss: 11.7942
2026-02-09 20:38:24,216 - __main__ - INFO - Epoch 10: Train Loss: 13.0584, Val Loss: 16.5016
2026-02-09 20:38:24,351 - __main__ - INFO - Epoch 11, Batch 0, Loss: 13.1087
2026-02-09 20:38:24,543 - __main__ - INFO - Epoch 11, Batch 50, Loss: 12.2815
2026-02-09 20:38:24,734 - __main__ - INFO - Epoch 11, Batch 100, Loss: 14.5169
2026-02-09 20:38:24,948 - __main__ - INFO - Epoch 11, Batch 150, Loss: 12.4626
2026-02-09 20:38:25,143 - __main__ - INFO - Epoch 11, Batch 200, Loss: 13.6870
2026-02-09 20:38:25,361 - __main__ - INFO - Epoch 11, Batch 250, Loss: 14.7497
2026-02-09 20:38:25,553 - __main__ - INFO - Epoch 11, Batch 300, Loss: 14.0413
2026-02-09 20:38:25,895 - __main__ - INFO - Epoch 11: Train Loss: 13.0236, Val Loss: 15.9433
2026-02-09 20:38:26,022 - __main__ - INFO - Epoch 12, Batch 0, Loss: 13.0214
2026-02-09 20:38:26,267 - __main__ - INFO - Epoch 12, Batch 50, Loss: 11.5932
2026-02-09 20:38:26,463 - __main__ - INFO - Epoch 12, Batch 100, Loss: 12.6162
2026-02-09 20:38:26,661 - __main__ - INFO - Epoch 12, Batch 150, Loss: 13.3586
2026-02-09 20:38:26,854 - __main__ - INFO - Epoch 12, Batch 200, Loss: 14.2356
2026-02-09 20:38:27,061 - __main__ - INFO - Epoch 12, Batch 250, Loss: 13.5355
2026-02-09 20:38:27,272 - __main__ - INFO - Epoch 12, Batch 300, Loss: 11.6894
2026-02-09 20:38:27,616 - __main__ - INFO - Epoch 12: Train Loss: 13.0673, Val Loss: 16.3390
2026-02-09 20:38:27,742 - __main__ - INFO - Epoch 13, Batch 0, Loss: 11.4465
2026-02-09 20:38:27,934 - __main__ - INFO - Epoch 13, Batch 50, Loss: 13.6140
2026-02-09 20:38:28,133 - __main__ - INFO - Epoch 13, Batch 100, Loss: 11.8302
2026-02-09 20:38:28,364 - __main__ - INFO - Epoch 13, Batch 150, Loss: 12.6139
2026-02-09 20:38:28,556 - __main__ - INFO - Epoch 13, Batch 200, Loss: 12.2840
2026-02-09 20:38:28,750 - __main__ - INFO - Epoch 13, Batch 250, Loss: 10.8162
2026-02-09 20:38:28,941 - __main__ - INFO - Epoch 13, Batch 300, Loss: 12.5705
2026-02-09 20:38:29,287 - __main__ - INFO - Epoch 13: Train Loss: 13.0300, Val Loss: 15.5707
2026-02-09 20:38:29,410 - __main__ - INFO - Epoch 14, Batch 0, Loss: 13.6742
2026-02-09 20:38:29,621 - __main__ - INFO - Epoch 14, Batch 50, Loss: 12.0809
2026-02-09 20:38:29,818 - __main__ - INFO - Epoch 14, Batch 100, Loss: 12.1936
2026-02-09 20:38:30,016 - __main__ - INFO - Epoch 14, Batch 150, Loss: 13.5375
2026-02-09 20:38:30,248 - __main__ - INFO - Epoch 14, Batch 200, Loss: 13.1412
2026-02-09 20:38:30,441 - __main__ - INFO - Epoch 14, Batch 250, Loss: 12.0665
2026-02-09 20:38:30,645 - __main__ - INFO - Epoch 14, Batch 300, Loss: 15.3975
2026-02-09 20:38:30,990 - __main__ - INFO - Epoch 14: Train Loss: 13.0461, Val Loss: 16.3456
2026-02-09 20:38:31,118 - __main__ - INFO - Epoch 15, Batch 0, Loss: 13.0908
2026-02-09 20:38:31,320 - __main__ - INFO - Epoch 15, Batch 50, Loss: 13.8681
2026-02-09 20:38:31,518 - __main__ - INFO - Epoch 15, Batch 100, Loss: 12.7172
2026-02-09 20:38:31,732 - __main__ - INFO - Epoch 15, Batch 150, Loss: 11.6883
2026-02-09 20:38:31,938 - __main__ - INFO - Epoch 15, Batch 200, Loss: 13.3506
2026-02-09 20:38:32,135 - __main__ - INFO - Epoch 15, Batch 250, Loss: 14.2465
2026-02-09 20:38:32,379 - __main__ - INFO - Epoch 15, Batch 300, Loss: 13.5403
2026-02-09 20:38:32,719 - __main__ - INFO - Epoch 15: Train Loss: 13.0579, Val Loss: 15.5361
2026-02-09 20:38:32,820 - __main__ - INFO - Epoch 16, Batch 0, Loss: 14.5251
2026-02-09 20:38:33,045 - __main__ - INFO - Epoch 16, Batch 50, Loss: 12.7848
2026-02-09 20:38:33,258 - __main__ - INFO - Epoch 16, Batch 100, Loss: 12.5423
2026-02-09 20:38:33,454 - __main__ - INFO - Epoch 16, Batch 150, Loss: 13.8240
2026-02-09 20:38:33,649 - __main__ - INFO - Epoch 16, Batch 200, Loss: 13.2208
2026-02-09 20:38:33,843 - __main__ - INFO - Epoch 16, Batch 250, Loss: 12.4313
2026-02-09 20:38:34,045 - __main__ - INFO - Epoch 16, Batch 300, Loss: 11.7154
2026-02-09 20:38:34,386 - __main__ - INFO - Epoch 16: Train Loss: 13.0464, Val Loss: 15.6655
2026-02-09 20:38:34,511 - __main__ - INFO - Epoch 17, Batch 0, Loss: 13.8411
2026-02-09 20:38:34,706 - __main__ - INFO - Epoch 17, Batch 50, Loss: 13.9883
2026-02-09 20:38:34,902 - __main__ - INFO - Epoch 17, Batch 100, Loss: 13.4532
2026-02-09 20:38:35,099 - __main__ - INFO - Epoch 17, Batch 150, Loss: 12.8464
2026-02-09 20:38:35,307 - __main__ - INFO - Epoch 17, Batch 200, Loss: 14.3972
2026-02-09 20:38:35,507 - __main__ - INFO - Epoch 17, Batch 250, Loss: 12.6200
2026-02-09 20:38:35,706 - __main__ - INFO - Epoch 17, Batch 300, Loss: 12.7029
2026-02-09 20:38:36,051 - __main__ - INFO - Epoch 17: Train Loss: 13.0570, Val Loss: 15.7427
2026-02-09 20:38:36,184 - __main__ - INFO - Epoch 18, Batch 0, Loss: 14.1960
2026-02-09 20:38:36,405 - __main__ - INFO - Epoch 18, Batch 50, Loss: 15.6215
2026-02-09 20:38:36,603 - __main__ - INFO - Epoch 18, Batch 100, Loss: 14.6942
2026-02-09 20:38:36,797 - __main__ - INFO - Epoch 18, Batch 150, Loss: 13.1839
2026-02-09 20:38:36,991 - __main__ - INFO - Epoch 18, Batch 200, Loss: 12.3185
2026-02-09 20:38:37,201 - __main__ - INFO - Epoch 18, Batch 250, Loss: 14.0886
2026-02-09 20:38:37,402 - __main__ - INFO - Epoch 18, Batch 300, Loss: 12.9455
2026-02-09 20:38:37,744 - __main__ - INFO - Epoch 18: Train Loss: 13.0548, Val Loss: 15.6654
2026-02-09 20:38:37,868 - __main__ - INFO - Epoch 19, Batch 0, Loss: 14.0995
2026-02-09 20:38:38,076 - __main__ - INFO - Epoch 19, Batch 50, Loss: 13.9962
2026-02-09 20:38:38,318 - __main__ - INFO - Epoch 19, Batch 100, Loss: 13.9111
2026-02-09 20:38:38,530 - __main__ - INFO - Epoch 19, Batch 150, Loss: 13.3696
2026-02-09 20:38:38,722 - __main__ - INFO - Epoch 19, Batch 200, Loss: 10.8520
2026-02-09 20:38:38,937 - __main__ - INFO - Epoch 19, Batch 250, Loss: 13.2476
2026-02-09 20:38:39,142 - __main__ - INFO - Epoch 19, Batch 300, Loss: 13.7975
2026-02-09 20:38:39,483 - __main__ - INFO - Epoch 19: Train Loss: 13.0167, Val Loss: 15.7452
2026-02-09 20:38:39,584 - __main__ - INFO - Epoch 20, Batch 0, Loss: 11.6998
2026-02-09 20:38:39,820 - __main__ - INFO - Epoch 20, Batch 50, Loss: 12.9320
2026-02-09 20:38:40,018 - __main__ - INFO - Epoch 20, Batch 100, Loss: 12.5773
2026-02-09 20:38:40,256 - __main__ - INFO - Epoch 20, Batch 150, Loss: 12.4266
2026-02-09 20:38:40,450 - __main__ - INFO - Epoch 20, Batch 200, Loss: 12.6520
2026-02-09 20:38:40,641 - __main__ - INFO - Epoch 20, Batch 250, Loss: 12.0306
2026-02-09 20:38:40,837 - __main__ - INFO - Epoch 20, Batch 300, Loss: 11.8092
2026-02-09 20:38:41,158 - __main__ - INFO - Epoch 20: Train Loss: 13.0488, Val Loss: 15.9444
2026-02-09 20:38:41,285 - __main__ - INFO - Epoch 21, Batch 0, Loss: 12.6934
2026-02-09 20:38:41,482 - __main__ - INFO - Epoch 21, Batch 50, Loss: 13.0273
2026-02-09 20:38:41,687 - __main__ - INFO - Epoch 21, Batch 100, Loss: 11.2398
2026-02-09 20:38:41,882 - __main__ - INFO - Epoch 21, Batch 150, Loss: 13.1529
2026-02-09 20:38:42,073 - __main__ - INFO - Epoch 21, Batch 200, Loss: 16.0418
2026-02-09 20:38:42,304 - __main__ - INFO - Epoch 21, Batch 250, Loss: 14.4546
2026-02-09 20:38:42,497 - __main__ - INFO - Epoch 21, Batch 300, Loss: 13.3505
2026-02-09 20:38:42,827 - __main__ - INFO - Epoch 21: Train Loss: 13.0496, Val Loss: 15.3717
2026-02-09 20:38:42,947 - __main__ - INFO - Epoch 22, Batch 0, Loss: 14.3317
2026-02-09 20:38:43,137 - __main__ - INFO - Epoch 22, Batch 50, Loss: 12.7628
2026-02-09 20:38:43,352 - __main__ - INFO - Epoch 22, Batch 100, Loss: 12.9705
2026-02-09 20:38:43,555 - __main__ - INFO - Epoch 22, Batch 150, Loss: 12.2217
2026-02-09 20:38:43,754 - __main__ - INFO - Epoch 22, Batch 200, Loss: 13.1458
2026-02-09 20:38:43,943 - __main__ - INFO - Epoch 22, Batch 250, Loss: 11.0271
2026-02-09 20:38:44,134 - __main__ - INFO - Epoch 22, Batch 300, Loss: 13.0689
2026-02-09 20:38:44,492 - __main__ - INFO - Epoch 22: Train Loss: 13.0451, Val Loss: 15.4132
2026-02-09 20:38:44,625 - __main__ - INFO - Epoch 23, Batch 0, Loss: 13.3576
2026-02-09 20:38:44,818 - __main__ - INFO - Epoch 23, Batch 50, Loss: 13.0380
2026-02-09 20:38:45,011 - __main__ - INFO - Epoch 23, Batch 100, Loss: 13.7753
2026-02-09 20:38:45,229 - __main__ - INFO - Epoch 23, Batch 150, Loss: 14.3969
2026-02-09 20:38:45,426 - __main__ - INFO - Epoch 23, Batch 200, Loss: 11.2243
2026-02-09 20:38:45,614 - __main__ - INFO - Epoch 23, Batch 250, Loss: 11.9860
2026-02-09 20:38:45,806 - __main__ - INFO - Epoch 23, Batch 300, Loss: 11.2470
2026-02-09 20:38:46,137 - __main__ - INFO - Epoch 23: Train Loss: 13.0303, Val Loss: 15.4848
2026-02-09 20:38:46,253 - __main__ - INFO - Epoch 24, Batch 0, Loss: 12.5726
2026-02-09 20:38:46,479 - __main__ - INFO - Epoch 24, Batch 50, Loss: 12.8419
2026-02-09 20:38:46,674 - __main__ - INFO - Epoch 24, Batch 100, Loss: 13.6521
2026-02-09 20:38:46,884 - __main__ - INFO - Epoch 24, Batch 150, Loss: 13.3067
2026-02-09 20:38:47,083 - __main__ - INFO - Epoch 24, Batch 200, Loss: 13.0175
2026-02-09 20:38:47,304 - __main__ - INFO - Epoch 24, Batch 250, Loss: 10.8300
2026-02-09 20:38:47,506 - __main__ - INFO - Epoch 24, Batch 300, Loss: 13.4767
2026-02-09 20:38:47,852 - __main__ - INFO - Epoch 24: Train Loss: 13.0128, Val Loss: 15.6905
2026-02-09 20:38:47,970 - __main__ - INFO - Epoch 25, Batch 0, Loss: 13.4657
2026-02-09 20:38:48,170 - __main__ - INFO - Epoch 25, Batch 50, Loss: 12.4665
2026-02-09 20:38:48,397 - __main__ - INFO - Epoch 25, Batch 100, Loss: 14.7677
2026-02-09 20:38:48,597 - __main__ - INFO - Epoch 25, Batch 150, Loss: 13.6912
2026-02-09 20:38:48,788 - __main__ - INFO - Epoch 25, Batch 200, Loss: 11.7960
2026-02-09 20:38:48,991 - __main__ - INFO - Epoch 25, Batch 250, Loss: 13.0257
2026-02-09 20:38:49,191 - __main__ - INFO - Epoch 25, Batch 300, Loss: 10.6482
2026-02-09 20:38:49,514 - __main__ - INFO - Epoch 25: Train Loss: 13.0511, Val Loss: 15.8153
2026-02-09 20:38:49,629 - __main__ - INFO - Epoch 26, Batch 0, Loss: 12.7529
2026-02-09 20:38:49,831 - __main__ - INFO - Epoch 26, Batch 50, Loss: 13.2251
2026-02-09 20:38:50,032 - __main__ - INFO - Epoch 26, Batch 100, Loss: 12.8263
2026-02-09 20:38:50,271 - __main__ - INFO - Epoch 26, Batch 150, Loss: 12.9867
2026-02-09 20:38:50,464 - __main__ - INFO - Epoch 26, Batch 200, Loss: 14.9489
2026-02-09 20:38:50,656 - __main__ - INFO - Epoch 26, Batch 250, Loss: 12.4161
2026-02-09 20:38:50,856 - __main__ - INFO - Epoch 26, Batch 300, Loss: 13.2528
2026-02-09 20:38:51,191 - __main__ - INFO - Epoch 26: Train Loss: 13.0056, Val Loss: 15.4093
2026-02-09 20:38:51,313 - __main__ - INFO - Epoch 27, Batch 0, Loss: 10.9524
2026-02-09 20:38:51,534 - __main__ - INFO - Epoch 27, Batch 50, Loss: 15.0265
2026-02-09 20:38:51,732 - __main__ - INFO - Epoch 27, Batch 100, Loss: 12.7265
2026-02-09 20:38:51,950 - __main__ - INFO - Epoch 27, Batch 150, Loss: 13.6273
2026-02-09 20:38:52,148 - __main__ - INFO - Epoch 27, Batch 200, Loss: 12.4703
2026-02-09 20:38:52,378 - __main__ - INFO - Epoch 27, Batch 250, Loss: 12.2157
2026-02-09 20:38:52,571 - __main__ - INFO - Epoch 27, Batch 300, Loss: 13.9056
2026-02-09 20:38:52,911 - __main__ - INFO - Epoch 27: Train Loss: 13.0319, Val Loss: 15.6287
2026-02-09 20:38:53,031 - __main__ - INFO - Epoch 28, Batch 0, Loss: 12.5563
2026-02-09 20:38:53,265 - __main__ - INFO - Epoch 28, Batch 50, Loss: 11.7796
2026-02-09 20:38:53,454 - __main__ - INFO - Epoch 28, Batch 100, Loss: 14.4935
2026-02-09 20:38:53,661 - __main__ - INFO - Epoch 28, Batch 150, Loss: 13.7411
2026-02-09 20:38:53,862 - __main__ - INFO - Epoch 28, Batch 200, Loss: 13.4846
2026-02-09 20:38:54,058 - __main__ - INFO - Epoch 28, Batch 250, Loss: 12.1947
2026-02-09 20:38:54,298 - __main__ - INFO - Epoch 28, Batch 300, Loss: 13.3841
2026-02-09 20:38:54,614 - __main__ - INFO - Epoch 28: Train Loss: 13.0285, Val Loss: 15.6819
2026-02-09 20:38:54,736 - __main__ - INFO - Epoch 29, Batch 0, Loss: 12.7161
2026-02-09 20:38:54,940 - __main__ - INFO - Epoch 29, Batch 50, Loss: 13.7263
2026-02-09 20:38:55,149 - __main__ - INFO - Epoch 29, Batch 100, Loss: 11.8029
2026-02-09 20:38:55,369 - __main__ - INFO - Epoch 29, Batch 150, Loss: 12.0333
2026-02-09 20:38:55,582 - __main__ - INFO - Epoch 29, Batch 200, Loss: 11.9101
2026-02-09 20:38:55,771 - __main__ - INFO - Epoch 29, Batch 250, Loss: 14.4886
2026-02-09 20:38:55,966 - __main__ - INFO - Epoch 29, Batch 300, Loss: 12.1566
2026-02-09 20:38:56,339 - __main__ - INFO - Epoch 29: Train Loss: 13.0317, Val Loss: 16.1585
2026-02-09 20:38:56,455 - __main__ - INFO - Epoch 30, Batch 0, Loss: 13.1799
2026-02-09 20:38:56,666 - __main__ - INFO - Epoch 30, Batch 50, Loss: 11.8696
2026-02-09 20:38:56,872 - __main__ - INFO - Epoch 30, Batch 100, Loss: 11.9101
2026-02-09 20:38:57,074 - __main__ - INFO - Epoch 30, Batch 150, Loss: 12.7382
2026-02-09 20:38:57,291 - __main__ - INFO - Epoch 30, Batch 200, Loss: 12.4805
2026-02-09 20:38:57,488 - __main__ - INFO - Epoch 30, Batch 250, Loss: 11.6580
2026-02-09 20:38:57,688 - __main__ - INFO - Epoch 30, Batch 300, Loss: 10.9791
2026-02-09 20:38:58,022 - __main__ - INFO - Epoch 30: Train Loss: 13.0209, Val Loss: 15.3484
2026-02-09 20:38:58,158 - __main__ - INFO - Epoch 31, Batch 0, Loss: 12.9840
2026-02-09 20:38:58,394 - __main__ - INFO - Epoch 31, Batch 50, Loss: 13.6056
2026-02-09 20:38:58,617 - __main__ - INFO - Epoch 31, Batch 100, Loss: 13.3401
2026-02-09 20:38:58,827 - __main__ - INFO - Epoch 31, Batch 150, Loss: 12.2779
2026-02-09 20:38:59,024 - __main__ - INFO - Epoch 31, Batch 200, Loss: 13.3614
2026-02-09 20:38:59,231 - __main__ - INFO - Epoch 31, Batch 250, Loss: 14.8942
2026-02-09 20:38:59,438 - __main__ - INFO - Epoch 31, Batch 300, Loss: 13.7474
2026-02-09 20:38:59,772 - __main__ - INFO - Epoch 31: Train Loss: 12.9984, Val Loss: 16.4530
2026-02-09 20:38:59,886 - __main__ - INFO - Epoch 32, Batch 0, Loss: 13.1194
2026-02-09 20:39:00,086 - __main__ - INFO - Epoch 32, Batch 50, Loss: 11.4339
2026-02-09 20:39:00,318 - __main__ - INFO - Epoch 32, Batch 100, Loss: 14.0160
2026-02-09 20:39:00,531 - __main__ - INFO - Epoch 32, Batch 150, Loss: 12.1916
2026-02-09 20:39:00,758 - __main__ - INFO - Epoch 32, Batch 200, Loss: 12.0157
2026-02-09 20:39:00,951 - __main__ - INFO - Epoch 32, Batch 250, Loss: 13.9578
2026-02-09 20:39:01,149 - __main__ - INFO - Epoch 32, Batch 300, Loss: 11.9109
2026-02-09 20:39:01,476 - __main__ - INFO - Epoch 32: Train Loss: 13.0167, Val Loss: 15.6489
2026-02-09 20:39:01,571 - __main__ - INFO - Epoch 33, Batch 0, Loss: 11.9799
2026-02-09 20:39:01,800 - __main__ - INFO - Epoch 33, Batch 50, Loss: 13.4968
2026-02-09 20:39:01,996 - __main__ - INFO - Epoch 33, Batch 100, Loss: 11.3907
2026-02-09 20:39:02,210 - __main__ - INFO - Epoch 33, Batch 150, Loss: 13.8991
2026-02-09 20:39:02,430 - __main__ - INFO - Epoch 33, Batch 200, Loss: 11.4077
2026-02-09 20:39:02,624 - __main__ - INFO - Epoch 33, Batch 250, Loss: 13.0844
2026-02-09 20:39:02,823 - __main__ - INFO - Epoch 33, Batch 300, Loss: 12.3380
2026-02-09 20:39:03,144 - __main__ - INFO - Epoch 33: Train Loss: 13.0155, Val Loss: 15.8284
2026-02-09 20:39:03,273 - __main__ - INFO - Epoch 34, Batch 0, Loss: 14.0881
2026-02-09 20:39:03,479 - __main__ - INFO - Epoch 34, Batch 50, Loss: 11.7993
2026-02-09 20:39:03,674 - __main__ - INFO - Epoch 34, Batch 100, Loss: 12.5012
2026-02-09 20:39:03,871 - __main__ - INFO - Epoch 34, Batch 150, Loss: 13.1262
2026-02-09 20:39:04,075 - __main__ - INFO - Epoch 34, Batch 200, Loss: 13.2655
2026-02-09 20:39:04,312 - __main__ - INFO - Epoch 34, Batch 250, Loss: 13.3182
2026-02-09 20:39:04,514 - __main__ - INFO - Epoch 34, Batch 300, Loss: 12.6064
2026-02-09 20:39:04,836 - __main__ - INFO - Epoch 34: Train Loss: 13.0045, Val Loss: 15.4871
2026-02-09 20:39:04,953 - __main__ - INFO - Epoch 35, Batch 0, Loss: 17.4461
2026-02-09 20:39:05,159 - __main__ - INFO - Epoch 35, Batch 50, Loss: 12.5428
2026-02-09 20:39:05,366 - __main__ - INFO - Epoch 35, Batch 100, Loss: 12.8008
2026-02-09 20:39:05,575 - __main__ - INFO - Epoch 35, Batch 150, Loss: 15.3556
2026-02-09 20:39:05,769 - __main__ - INFO - Epoch 35, Batch 200, Loss: 13.6005
2026-02-09 20:39:05,958 - __main__ - INFO - Epoch 35, Batch 250, Loss: 11.6183
2026-02-09 20:39:06,151 - __main__ - INFO - Epoch 35, Batch 300, Loss: 12.5038
2026-02-09 20:39:06,495 - __main__ - INFO - Epoch 35: Train Loss: 12.9905, Val Loss: 15.7434
2026-02-09 20:39:06,613 - __main__ - INFO - Epoch 36, Batch 0, Loss: 13.3666
2026-02-09 20:39:06,807 - __main__ - INFO - Epoch 36, Batch 50, Loss: 11.6418
2026-02-09 20:39:06,998 - __main__ - INFO - Epoch 36, Batch 100, Loss: 14.5741
2026-02-09 20:39:07,214 - __main__ - INFO - Epoch 36, Batch 150, Loss: 11.5653
2026-02-09 20:39:07,405 - __main__ - INFO - Epoch 36, Batch 200, Loss: 12.9031
2026-02-09 20:39:07,600 - __main__ - INFO - Epoch 36, Batch 250, Loss: 12.6169
2026-02-09 20:39:07,789 - __main__ - INFO - Epoch 36, Batch 300, Loss: 12.6443
2026-02-09 20:39:08,103 - __main__ - INFO - Epoch 36: Train Loss: 13.0022, Val Loss: 15.9677
2026-02-09 20:39:08,239 - __main__ - INFO - Epoch 37, Batch 0, Loss: 11.3603
2026-02-09 20:39:08,455 - __main__ - INFO - Epoch 37, Batch 50, Loss: 13.5188
2026-02-09 20:39:08,649 - __main__ - INFO - Epoch 37, Batch 100, Loss: 11.1381
2026-02-09 20:39:08,849 - __main__ - INFO - Epoch 37, Batch 150, Loss: 12.7914
2026-02-09 20:39:09,063 - __main__ - INFO - Epoch 37, Batch 200, Loss: 12.9232
2026-02-09 20:39:09,268 - __main__ - INFO - Epoch 37, Batch 250, Loss: 12.5479
2026-02-09 20:39:09,462 - __main__ - INFO - Epoch 37, Batch 300, Loss: 10.5693
2026-02-09 20:39:09,785 - __main__ - INFO - Epoch 37: Train Loss: 13.0064, Val Loss: 15.3831
2026-02-09 20:39:09,907 - __main__ - INFO - Epoch 38, Batch 0, Loss: 12.2437
2026-02-09 20:39:10,110 - __main__ - INFO - Epoch 38, Batch 50, Loss: 12.8268
2026-02-09 20:39:10,339 - __main__ - INFO - Epoch 38, Batch 100, Loss: 10.5512
2026-02-09 20:39:10,555 - __main__ - INFO - Epoch 38, Batch 150, Loss: 11.9139
2026-02-09 20:39:10,745 - __main__ - INFO - Epoch 38, Batch 200, Loss: 13.6448
2026-02-09 20:39:10,952 - __main__ - INFO - Epoch 38, Batch 250, Loss: 12.4108
2026-02-09 20:39:11,152 - __main__ - INFO - Epoch 38, Batch 300, Loss: 14.5940
2026-02-09 20:39:11,502 - __main__ - INFO - Epoch 38: Train Loss: 12.9819, Val Loss: 16.3110
2026-02-09 20:39:11,620 - __main__ - INFO - Epoch 39, Batch 0, Loss: 12.4125
2026-02-09 20:39:11,810 - __main__ - INFO - Epoch 39, Batch 50, Loss: 12.9118
2026-02-09 20:39:12,014 - __main__ - INFO - Epoch 39, Batch 100, Loss: 11.8643
2026-02-09 20:39:12,227 - __main__ - INFO - Epoch 39, Batch 150, Loss: 13.1072
2026-02-09 20:39:12,441 - __main__ - INFO - Epoch 39, Batch 200, Loss: 12.7321
2026-02-09 20:39:12,648 - __main__ - INFO - Epoch 39, Batch 250, Loss: 12.7924
2026-02-09 20:39:12,854 - __main__ - INFO - Epoch 39, Batch 300, Loss: 12.7945
2026-02-09 20:39:13,178 - __main__ - INFO - Epoch 39: Train Loss: 13.0116, Val Loss: 15.5991
2026-02-09 20:39:13,307 - __main__ - INFO - Epoch 40, Batch 0, Loss: 12.4861
2026-02-09 20:39:13,512 - __main__ - INFO - Epoch 40, Batch 50, Loss: 13.1456
2026-02-09 20:39:13,706 - __main__ - INFO - Epoch 40, Batch 100, Loss: 12.5994
2026-02-09 20:39:13,913 - __main__ - INFO - Epoch 40, Batch 150, Loss: 13.7655
2026-02-09 20:39:14,110 - __main__ - INFO - Epoch 40, Batch 200, Loss: 16.2680
2026-02-09 20:39:14,340 - __main__ - INFO - Epoch 40, Batch 250, Loss: 13.2786
2026-02-09 20:39:14,540 - __main__ - INFO - Epoch 40, Batch 300, Loss: 12.9339
2026-02-09 20:39:14,869 - __main__ - INFO - Epoch 40: Train Loss: 12.9877, Val Loss: 15.4881
2026-02-09 20:39:14,962 - __main__ - INFO - Epoch 41, Batch 0, Loss: 11.8472
2026-02-09 20:39:15,175 - __main__ - INFO - Epoch 41, Batch 50, Loss: 13.2631
2026-02-09 20:39:15,379 - __main__ - INFO - Epoch 41, Batch 100, Loss: 12.4830
2026-02-09 20:39:15,585 - __main__ - INFO - Epoch 41, Batch 150, Loss: 12.7630
2026-02-09 20:39:15,775 - __main__ - INFO - Epoch 41, Batch 200, Loss: 14.4851
2026-02-09 20:39:15,972 - __main__ - INFO - Epoch 41, Batch 250, Loss: 12.0182
2026-02-09 20:39:16,174 - __main__ - INFO - Epoch 41, Batch 300, Loss: 11.9516
2026-02-09 20:39:16,538 - __main__ - INFO - Epoch 41: Train Loss: 12.9822, Val Loss: 16.2330
2026-02-09 20:39:16,655 - __main__ - INFO - Epoch 42, Batch 0, Loss: 12.9717
2026-02-09 20:39:16,867 - __main__ - INFO - Epoch 42, Batch 50, Loss: 12.7780
2026-02-09 20:39:17,079 - __main__ - INFO - Epoch 42, Batch 100, Loss: 11.6732
2026-02-09 20:39:17,298 - __main__ - INFO - Epoch 42, Batch 150, Loss: 11.3823
2026-02-09 20:39:17,499 - __main__ - INFO - Epoch 42, Batch 200, Loss: 14.6907
2026-02-09 20:39:17,700 - __main__ - INFO - Epoch 42, Batch 250, Loss: 12.2360
2026-02-09 20:39:17,895 - __main__ - INFO - Epoch 42, Batch 300, Loss: 13.4861
2026-02-09 20:39:18,235 - __main__ - INFO - Epoch 42: Train Loss: 12.9936, Val Loss: 15.7740
2026-02-09 20:39:18,362 - __main__ - INFO - Epoch 43, Batch 0, Loss: 12.6041
2026-02-09 20:39:18,557 - __main__ - INFO - Epoch 43, Batch 50, Loss: 12.8807
2026-02-09 20:39:18,748 - __main__ - INFO - Epoch 43, Batch 100, Loss: 13.6367
2026-02-09 20:39:18,948 - __main__ - INFO - Epoch 43, Batch 150, Loss: 13.2829
2026-02-09 20:39:19,142 - __main__ - INFO - Epoch 43, Batch 200, Loss: 12.4101
2026-02-09 20:39:19,352 - __main__ - INFO - Epoch 43, Batch 250, Loss: 13.9674
2026-02-09 20:39:19,568 - __main__ - INFO - Epoch 43, Batch 300, Loss: 13.9646
2026-02-09 20:39:19,889 - __main__ - INFO - Epoch 43: Train Loss: 12.9822, Val Loss: 15.5211
2026-02-09 20:39:20,003 - __main__ - INFO - Epoch 44, Batch 0, Loss: 13.1030
2026-02-09 20:39:20,198 - __main__ - INFO - Epoch 44, Batch 50, Loss: 13.1324
2026-02-09 20:39:20,445 - __main__ - INFO - Epoch 44, Batch 100, Loss: 14.0257
2026-02-09 20:39:20,650 - __main__ - INFO - Epoch 44, Batch 150, Loss: 14.1198
2026-02-09 20:39:20,842 - __main__ - INFO - Epoch 44, Batch 200, Loss: 14.6707
2026-02-09 20:39:21,036 - __main__ - INFO - Epoch 44, Batch 250, Loss: 11.1212
2026-02-09 20:39:21,241 - __main__ - INFO - Epoch 44, Batch 300, Loss: 14.5981
2026-02-09 20:39:21,568 - __main__ - INFO - Epoch 44: Train Loss: 13.0135, Val Loss: 15.3879
2026-02-09 20:39:21,708 - __main__ - INFO - Epoch 45, Batch 0, Loss: 14.0623
2026-02-09 20:39:21,903 - __main__ - INFO - Epoch 45, Batch 50, Loss: 11.6261
2026-02-09 20:39:22,095 - __main__ - INFO - Epoch 45, Batch 100, Loss: 15.5673
2026-02-09 20:39:22,344 - __main__ - INFO - Epoch 45, Batch 150, Loss: 12.5317
2026-02-09 20:39:22,548 - __main__ - INFO - Epoch 45, Batch 200, Loss: 12.8713
2026-02-09 20:39:22,741 - __main__ - INFO - Epoch 45, Batch 250, Loss: 12.8746
2026-02-09 20:39:22,932 - __main__ - INFO - Epoch 45, Batch 300, Loss: 13.0169
2026-02-09 20:39:23,274 - __main__ - INFO - Epoch 45: Train Loss: 12.9845, Val Loss: 15.8158
2026-02-09 20:39:23,389 - __main__ - INFO - Epoch 46, Batch 0, Loss: 13.1943
2026-02-09 20:39:23,579 - __main__ - INFO - Epoch 46, Batch 50, Loss: 13.1411
2026-02-09 20:39:23,768 - __main__ - INFO - Epoch 46, Batch 100, Loss: 13.3537
2026-02-09 20:39:23,972 - __main__ - INFO - Epoch 46, Batch 150, Loss: 14.4299
2026-02-09 20:39:24,179 - __main__ - INFO - Epoch 46, Batch 200, Loss: 14.5003
2026-02-09 20:39:24,415 - __main__ - INFO - Epoch 46, Batch 250, Loss: 12.5626
2026-02-09 20:39:24,607 - __main__ - INFO - Epoch 46, Batch 300, Loss: 14.1759
2026-02-09 20:39:24,931 - __main__ - INFO - Epoch 46: Train Loss: 12.9886, Val Loss: 15.7880
2026-02-09 20:39:25,046 - __main__ - INFO - Epoch 47, Batch 0, Loss: 13.6687
2026-02-09 20:39:25,248 - __main__ - INFO - Epoch 47, Batch 50, Loss: 12.0397
2026-02-09 20:39:25,446 - __main__ - INFO - Epoch 47, Batch 100, Loss: 15.1439
2026-02-09 20:39:25,649 - __main__ - INFO - Epoch 47, Batch 150, Loss: 13.8105
2026-02-09 20:39:25,836 - __main__ - INFO - Epoch 47, Batch 200, Loss: 12.7129
2026-02-09 20:39:26,023 - __main__ - INFO - Epoch 47, Batch 250, Loss: 12.3690
2026-02-09 20:39:26,210 - __main__ - INFO - Epoch 47, Batch 300, Loss: 12.0191
2026-02-09 20:39:26,548 - __main__ - INFO - Epoch 47: Train Loss: 12.9766, Val Loss: 15.6631
2026-02-09 20:39:26,663 - __main__ - INFO - Epoch 48, Batch 0, Loss: 12.7807
2026-02-09 20:39:26,857 - __main__ - INFO - Epoch 48, Batch 50, Loss: 12.4319
2026-02-09 20:39:27,059 - __main__ - INFO - Epoch 48, Batch 100, Loss: 13.4591
2026-02-09 20:39:27,270 - __main__ - INFO - Epoch 48, Batch 150, Loss: 13.3966
2026-02-09 20:39:27,459 - __main__ - INFO - Epoch 48, Batch 200, Loss: 14.8406
2026-02-09 20:39:27,656 - __main__ - INFO - Epoch 48, Batch 250, Loss: 12.3870
2026-02-09 20:39:27,861 - __main__ - INFO - Epoch 48, Batch 300, Loss: 12.9945
2026-02-09 20:39:28,173 - __main__ - INFO - Epoch 48: Train Loss: 12.9943, Val Loss: 15.5278
2026-02-09 20:39:28,323 - __main__ - INFO - Epoch 49, Batch 0, Loss: 12.6789
2026-02-09 20:39:28,519 - __main__ - INFO - Epoch 49, Batch 50, Loss: 12.9412
2026-02-09 20:39:28,715 - __main__ - INFO - Epoch 49, Batch 100, Loss: 11.9639
2026-02-09 20:39:28,910 - __main__ - INFO - Epoch 49, Batch 150, Loss: 12.5889
2026-02-09 20:39:29,103 - __main__ - INFO - Epoch 49, Batch 200, Loss: 13.8375
2026-02-09 20:39:29,320 - __main__ - INFO - Epoch 49, Batch 250, Loss: 13.8267
2026-02-09 20:39:29,530 - __main__ - INFO - Epoch 49, Batch 300, Loss: 12.4357
2026-02-09 20:39:29,861 - __main__ - INFO - Epoch 49: Train Loss: 13.0004, Val Loss: 15.4754
2026-02-09 20:39:29,981 - __main__ - INFO - Epoch 50, Batch 0, Loss: 14.1714
2026-02-09 20:39:30,202 - __main__ - INFO - Epoch 50, Batch 50, Loss: 13.5270
2026-02-09 20:39:30,450 - __main__ - INFO - Epoch 50, Batch 100, Loss: 13.1389
2026-02-09 20:39:30,671 - __main__ - INFO - Epoch 50, Batch 150, Loss: 11.5046
2026-02-09 20:39:30,884 - __main__ - INFO - Epoch 50, Batch 200, Loss: 12.5142
2026-02-09 20:39:31,096 - __main__ - INFO - Epoch 50, Batch 250, Loss: 12.4178
2026-02-09 20:39:31,317 - __main__ - INFO - Epoch 50, Batch 300, Loss: 10.7165
2026-02-09 20:39:31,660 - __main__ - INFO - Epoch 50: Train Loss: 12.9943, Val Loss: 15.7047
2026-02-09 20:39:31,776 - __main__ - INFO - Epoch 51, Batch 0, Loss: 14.2801
2026-02-09 20:39:31,998 - __main__ - INFO - Epoch 51, Batch 50, Loss: 13.7620
2026-02-09 20:39:32,212 - __main__ - INFO - Epoch 51, Batch 100, Loss: 11.4707
2026-02-09 20:39:32,472 - __main__ - INFO - Epoch 51, Batch 150, Loss: 12.7745
2026-02-09 20:39:32,686 - __main__ - INFO - Epoch 51, Batch 200, Loss: 13.3219
2026-02-09 20:39:32,892 - __main__ - INFO - Epoch 51, Batch 250, Loss: 12.2857
2026-02-09 20:39:33,096 - __main__ - INFO - Epoch 51, Batch 300, Loss: 12.1357
2026-02-09 20:39:33,433 - __main__ - INFO - Epoch 51: Train Loss: 12.9684, Val Loss: 15.5151
2026-02-09 20:39:33,554 - __main__ - INFO - Epoch 52, Batch 0, Loss: 12.6817
2026-02-09 20:39:33,770 - __main__ - INFO - Epoch 52, Batch 50, Loss: 12.9863
2026-02-09 20:39:33,974 - __main__ - INFO - Epoch 52, Batch 100, Loss: 13.5176
2026-02-09 20:39:34,181 - __main__ - INFO - Epoch 52, Batch 150, Loss: 14.3647
2026-02-09 20:39:34,423 - __main__ - INFO - Epoch 52, Batch 200, Loss: 14.1039
2026-02-09 20:39:34,633 - __main__ - INFO - Epoch 52, Batch 250, Loss: 11.3111
2026-02-09 20:39:34,834 - __main__ - INFO - Epoch 52, Batch 300, Loss: 14.0554
2026-02-09 20:39:35,152 - __main__ - INFO - Epoch 52: Train Loss: 12.9740, Val Loss: 15.6729
2026-02-09 20:39:35,286 - __main__ - INFO - Epoch 53, Batch 0, Loss: 14.5188
2026-02-09 20:39:35,485 - __main__ - INFO - Epoch 53, Batch 50, Loss: 12.4518
2026-02-09 20:39:35,693 - __main__ - INFO - Epoch 53, Batch 100, Loss: 13.7766
2026-02-09 20:39:35,902 - __main__ - INFO - Epoch 53, Batch 150, Loss: 13.9346
2026-02-09 20:39:36,103 - __main__ - INFO - Epoch 53, Batch 200, Loss: 10.8685
2026-02-09 20:39:36,354 - __main__ - INFO - Epoch 53, Batch 250, Loss: 12.2667
2026-02-09 20:39:36,562 - __main__ - INFO - Epoch 53, Batch 300, Loss: 12.5446
2026-02-09 20:39:36,886 - __main__ - INFO - Epoch 53: Train Loss: 12.9622, Val Loss: 15.7921
2026-02-09 20:39:36,981 - __main__ - INFO - Epoch 54, Batch 0, Loss: 12.9826
2026-02-09 20:39:37,198 - __main__ - INFO - Epoch 54, Batch 50, Loss: 11.1522
2026-02-09 20:39:37,412 - __main__ - INFO - Epoch 54, Batch 100, Loss: 13.0848
2026-02-09 20:39:37,635 - __main__ - INFO - Epoch 54, Batch 150, Loss: 14.6782
2026-02-09 20:39:37,865 - __main__ - INFO - Epoch 54, Batch 200, Loss: 13.8396
2026-02-09 20:39:38,060 - __main__ - INFO - Epoch 54, Batch 250, Loss: 12.4859
2026-02-09 20:39:38,288 - __main__ - INFO - Epoch 54, Batch 300, Loss: 13.2607
2026-02-09 20:39:38,640 - __main__ - INFO - Epoch 54: Train Loss: 12.9685, Val Loss: 15.4416
2026-02-09 20:39:38,759 - __main__ - INFO - Epoch 55, Batch 0, Loss: 12.8078
2026-02-09 20:39:38,957 - __main__ - INFO - Epoch 55, Batch 50, Loss: 12.7574
2026-02-09 20:39:39,161 - __main__ - INFO - Epoch 55, Batch 100, Loss: 13.4101
2026-02-09 20:39:39,384 - __main__ - INFO - Epoch 55, Batch 150, Loss: 13.4914
2026-02-09 20:39:39,594 - __main__ - INFO - Epoch 55, Batch 200, Loss: 14.7667
2026-02-09 20:39:39,792 - __main__ - INFO - Epoch 55, Batch 250, Loss: 12.3913
2026-02-09 20:39:40,008 - __main__ - INFO - Epoch 55, Batch 300, Loss: 12.9000
2026-02-09 20:39:40,382 - __main__ - INFO - Epoch 55: Train Loss: 12.9785, Val Loss: 15.6395
2026-02-09 20:39:40,500 - __main__ - INFO - Epoch 56, Batch 0, Loss: 13.1504
2026-02-09 20:39:40,701 - __main__ - INFO - Epoch 56, Batch 50, Loss: 12.4985
2026-02-09 20:39:40,905 - __main__ - INFO - Epoch 56, Batch 100, Loss: 13.3363
2026-02-09 20:39:41,112 - __main__ - INFO - Epoch 56, Batch 150, Loss: 13.2717
2026-02-09 20:39:41,330 - __main__ - INFO - Epoch 56, Batch 200, Loss: 11.6562
2026-02-09 20:39:41,550 - __main__ - INFO - Epoch 56, Batch 250, Loss: 13.3022
2026-02-09 20:39:41,772 - __main__ - INFO - Epoch 56, Batch 300, Loss: 13.3988
2026-02-09 20:39:42,105 - __main__ - INFO - Epoch 56: Train Loss: 12.9740, Val Loss: 15.4415
2026-02-09 20:39:42,222 - __main__ - INFO - Epoch 57, Batch 0, Loss: 12.7116
2026-02-09 20:39:42,464 - __main__ - INFO - Epoch 57, Batch 50, Loss: 11.4553
2026-02-09 20:39:42,672 - __main__ - INFO - Epoch 57, Batch 100, Loss: 12.7888
2026-02-09 20:39:42,900 - __main__ - INFO - Epoch 57, Batch 150, Loss: 12.5417
2026-02-09 20:39:43,100 - __main__ - INFO - Epoch 57, Batch 200, Loss: 13.0045
2026-02-09 20:39:43,325 - __main__ - INFO - Epoch 57, Batch 250, Loss: 12.0167
2026-02-09 20:39:43,548 - __main__ - INFO - Epoch 57, Batch 300, Loss: 12.1583
2026-02-09 20:39:43,872 - __main__ - INFO - Epoch 57: Train Loss: 12.9975, Val Loss: 15.7406
2026-02-09 20:39:43,986 - __main__ - INFO - Epoch 58, Batch 0, Loss: 12.2472
2026-02-09 20:39:44,176 - __main__ - INFO - Epoch 58, Batch 50, Loss: 13.3593
2026-02-09 20:39:44,420 - __main__ - INFO - Epoch 58, Batch 100, Loss: 11.9860
2026-02-09 20:39:44,633 - __main__ - INFO - Epoch 58, Batch 150, Loss: 11.6580
2026-02-09 20:39:44,845 - __main__ - INFO - Epoch 58, Batch 200, Loss: 14.4550
2026-02-09 20:39:45,051 - __main__ - INFO - Epoch 58, Batch 250, Loss: 14.5173
2026-02-09 20:39:45,252 - __main__ - INFO - Epoch 58, Batch 300, Loss: 13.5358
2026-02-09 20:39:45,595 - __main__ - INFO - Epoch 58: Train Loss: 12.9754, Val Loss: 15.5227
2026-02-09 20:39:45,723 - __main__ - INFO - Epoch 59, Batch 0, Loss: 12.0570
2026-02-09 20:39:45,918 - __main__ - INFO - Epoch 59, Batch 50, Loss: 11.3333
2026-02-09 20:39:46,124 - __main__ - INFO - Epoch 59, Batch 100, Loss: 13.7399
2026-02-09 20:39:46,378 - __main__ - INFO - Epoch 59, Batch 150, Loss: 12.2546
2026-02-09 20:39:46,590 - __main__ - INFO - Epoch 59, Batch 200, Loss: 13.1239
2026-02-09 20:39:46,799 - __main__ - INFO - Epoch 59, Batch 250, Loss: 13.1446
2026-02-09 20:39:46,997 - __main__ - INFO - Epoch 59, Batch 300, Loss: 11.3488
2026-02-09 20:39:47,341 - __main__ - INFO - Epoch 59: Train Loss: 12.9668, Val Loss: 15.5472
2026-02-09 20:39:47,460 - __main__ - INFO - Epoch 60, Batch 0, Loss: 13.3792
2026-02-09 20:39:47,659 - __main__ - INFO - Epoch 60, Batch 50, Loss: 15.0596
2026-02-09 20:39:47,866 - __main__ - INFO - Epoch 60, Batch 100, Loss: 12.2510
2026-02-09 20:39:48,074 - __main__ - INFO - Epoch 60, Batch 150, Loss: 12.1007
2026-02-09 20:39:48,297 - __main__ - INFO - Epoch 60, Batch 200, Loss: 12.8691
2026-02-09 20:39:48,522 - __main__ - INFO - Epoch 60, Batch 250, Loss: 12.5076
2026-02-09 20:39:48,734 - __main__ - INFO - Epoch 60, Batch 300, Loss: 12.7719
2026-02-09 20:39:49,077 - __main__ - INFO - Epoch 60: Train Loss: 12.9702, Val Loss: 15.5722
2026-02-09 20:39:49,196 - __main__ - INFO - Epoch 61, Batch 0, Loss: 12.6801
2026-02-09 20:39:49,406 - __main__ - INFO - Epoch 61, Batch 50, Loss: 14.3519
2026-02-09 20:39:49,642 - __main__ - INFO - Epoch 61, Batch 100, Loss: 14.5769
2026-02-09 20:39:49,883 - __main__ - INFO - Epoch 61, Batch 150, Loss: 13.4431
2026-02-09 20:39:50,078 - __main__ - INFO - Epoch 61, Batch 200, Loss: 11.1215
2026-02-09 20:39:50,291 - __main__ - INFO - Epoch 61, Batch 250, Loss: 13.4801
2026-02-09 20:39:50,525 - __main__ - INFO - Epoch 61, Batch 300, Loss: 12.9209
2026-02-09 20:39:50,849 - __main__ - INFO - Epoch 61: Train Loss: 12.9612, Val Loss: 15.6399
2026-02-09 20:39:50,963 - __main__ - INFO - Epoch 62, Batch 0, Loss: 13.5153
2026-02-09 20:39:51,169 - __main__ - INFO - Epoch 62, Batch 50, Loss: 13.8684
2026-02-09 20:39:51,411 - __main__ - INFO - Epoch 62, Batch 100, Loss: 12.0307
2026-02-09 20:39:51,629 - __main__ - INFO - Epoch 62, Batch 150, Loss: 12.1656
2026-02-09 20:39:51,826 - __main__ - INFO - Epoch 62, Batch 200, Loss: 13.7720
2026-02-09 20:39:52,030 - __main__ - INFO - Epoch 62, Batch 250, Loss: 11.3175
2026-02-09 20:39:52,235 - __main__ - INFO - Epoch 62, Batch 300, Loss: 12.7335
2026-02-09 20:39:52,586 - __main__ - INFO - Epoch 62: Train Loss: 12.9615, Val Loss: 15.7887
2026-02-09 20:39:52,725 - __main__ - INFO - Epoch 63, Batch 0, Loss: 15.3368
2026-02-09 20:39:52,927 - __main__ - INFO - Epoch 63, Batch 50, Loss: 12.2464
2026-02-09 20:39:53,133 - __main__ - INFO - Epoch 63, Batch 100, Loss: 12.8356
2026-02-09 20:39:53,369 - __main__ - INFO - Epoch 63, Batch 150, Loss: 12.5021
2026-02-09 20:39:53,586 - __main__ - INFO - Epoch 63, Batch 200, Loss: 12.0996
2026-02-09 20:39:53,796 - __main__ - INFO - Epoch 63, Batch 250, Loss: 12.5242
2026-02-09 20:39:53,998 - __main__ - INFO - Epoch 63, Batch 300, Loss: 11.6354
2026-02-09 20:39:54,352 - __main__ - INFO - Epoch 63: Train Loss: 12.9723, Val Loss: 15.5367
2026-02-09 20:39:54,475 - __main__ - INFO - Epoch 64, Batch 0, Loss: 11.6586
2026-02-09 20:39:54,703 - __main__ - INFO - Epoch 64, Batch 50, Loss: 10.8731
2026-02-09 20:39:54,906 - __main__ - INFO - Epoch 64, Batch 100, Loss: 14.0322
2026-02-09 20:39:55,135 - __main__ - INFO - Epoch 64, Batch 150, Loss: 12.4301
2026-02-09 20:39:55,367 - __main__ - INFO - Epoch 64, Batch 200, Loss: 12.9835
2026-02-09 20:39:55,567 - __main__ - INFO - Epoch 64, Batch 250, Loss: 11.7915
2026-02-09 20:39:55,768 - __main__ - INFO - Epoch 64, Batch 300, Loss: 12.2210
2026-02-09 20:39:56,093 - __main__ - INFO - Epoch 64: Train Loss: 12.9573, Val Loss: 15.4371
2026-02-09 20:39:56,201 - __main__ - INFO - Epoch 65, Batch 0, Loss: 13.2070
2026-02-09 20:39:56,448 - __main__ - INFO - Epoch 65, Batch 50, Loss: 13.0868
2026-02-09 20:39:56,654 - __main__ - INFO - Epoch 65, Batch 100, Loss: 13.1862
2026-02-09 20:39:56,879 - __main__ - INFO - Epoch 65, Batch 150, Loss: 14.2518
2026-02-09 20:39:57,083 - __main__ - INFO - Epoch 65, Batch 200, Loss: 12.8250
2026-02-09 20:39:57,300 - __main__ - INFO - Epoch 65, Batch 250, Loss: 12.1689
2026-02-09 20:39:57,524 - __main__ - INFO - Epoch 65, Batch 300, Loss: 13.4865
2026-02-09 20:39:57,861 - __main__ - INFO - Epoch 65: Train Loss: 12.9748, Val Loss: 15.5181
2026-02-09 20:39:57,980 - __main__ - INFO - Epoch 66, Batch 0, Loss: 12.5135
2026-02-09 20:39:58,192 - __main__ - INFO - Epoch 66, Batch 50, Loss: 14.5702
2026-02-09 20:39:58,437 - __main__ - INFO - Epoch 66, Batch 100, Loss: 13.8043
2026-02-09 20:39:58,653 - __main__ - INFO - Epoch 66, Batch 150, Loss: 11.7490
2026-02-09 20:39:58,860 - __main__ - INFO - Epoch 66, Batch 200, Loss: 13.3696
2026-02-09 20:39:59,061 - __main__ - INFO - Epoch 66, Batch 250, Loss: 13.5631
2026-02-09 20:39:59,286 - __main__ - INFO - Epoch 66, Batch 300, Loss: 14.0348
2026-02-09 20:39:59,624 - __main__ - INFO - Epoch 66: Train Loss: 12.9772, Val Loss: 15.7578
2026-02-09 20:39:59,755 - __main__ - INFO - Epoch 67, Batch 0, Loss: 13.1161
2026-02-09 20:39:59,957 - __main__ - INFO - Epoch 67, Batch 50, Loss: 13.3376
2026-02-09 20:40:00,160 - __main__ - INFO - Epoch 67, Batch 100, Loss: 12.8571
2026-02-09 20:40:00,413 - __main__ - INFO - Epoch 67, Batch 150, Loss: 13.7521
2026-02-09 20:40:00,638 - __main__ - INFO - Epoch 67, Batch 200, Loss: 12.2451
2026-02-09 20:40:00,861 - __main__ - INFO - Epoch 67, Batch 250, Loss: 12.7939
2026-02-09 20:40:01,064 - __main__ - INFO - Epoch 67, Batch 300, Loss: 11.6506
2026-02-09 20:40:01,406 - __main__ - INFO - Epoch 67: Train Loss: 12.9514, Val Loss: 15.6503
2026-02-09 20:40:01,523 - __main__ - INFO - Epoch 68, Batch 0, Loss: 12.2926
2026-02-09 20:40:01,755 - __main__ - INFO - Epoch 68, Batch 50, Loss: 12.0852
2026-02-09 20:40:01,966 - __main__ - INFO - Epoch 68, Batch 100, Loss: 12.1609
2026-02-09 20:40:02,178 - __main__ - INFO - Epoch 68, Batch 150, Loss: 13.2691
2026-02-09 20:40:02,417 - __main__ - INFO - Epoch 68, Batch 200, Loss: 12.8574
2026-02-09 20:40:02,649 - __main__ - INFO - Epoch 68, Batch 250, Loss: 13.2990
2026-02-09 20:40:02,857 - __main__ - INFO - Epoch 68, Batch 300, Loss: 13.0946
2026-02-09 20:40:03,179 - __main__ - INFO - Epoch 68: Train Loss: 12.9635, Val Loss: 15.8653
2026-02-09 20:40:03,304 - __main__ - INFO - Epoch 69, Batch 0, Loss: 10.9878
2026-02-09 20:40:03,519 - __main__ - INFO - Epoch 69, Batch 50, Loss: 14.2023
2026-02-09 20:40:03,738 - __main__ - INFO - Epoch 69, Batch 100, Loss: 12.5120
2026-02-09 20:40:03,961 - __main__ - INFO - Epoch 69, Batch 150, Loss: 14.5469
2026-02-09 20:40:04,169 - __main__ - INFO - Epoch 69, Batch 200, Loss: 12.4472
2026-02-09 20:40:04,422 - __main__ - INFO - Epoch 69, Batch 250, Loss: 14.4829
2026-02-09 20:40:04,638 - __main__ - INFO - Epoch 69, Batch 300, Loss: 13.4137
2026-02-09 20:40:04,976 - __main__ - INFO - Epoch 69: Train Loss: 12.9720, Val Loss: 15.4731
2026-02-09 20:40:05,095 - __main__ - INFO - Epoch 70, Batch 0, Loss: 11.4257
2026-02-09 20:40:05,305 - __main__ - INFO - Epoch 70, Batch 50, Loss: 12.2582
2026-02-09 20:40:05,512 - __main__ - INFO - Epoch 70, Batch 100, Loss: 13.5055
2026-02-09 20:40:05,730 - __main__ - INFO - Epoch 70, Batch 150, Loss: 13.0645
2026-02-09 20:40:05,932 - __main__ - INFO - Epoch 70, Batch 200, Loss: 13.3547
2026-02-09 20:40:06,134 - __main__ - INFO - Epoch 70, Batch 250, Loss: 13.5679
2026-02-09 20:40:06,386 - __main__ - INFO - Epoch 70, Batch 300, Loss: 14.0027
2026-02-09 20:40:06,740 - __main__ - INFO - Epoch 70: Train Loss: 12.9630, Val Loss: 15.6236
2026-02-09 20:40:06,861 - __main__ - INFO - Epoch 71, Batch 0, Loss: 12.8783
2026-02-09 20:40:07,079 - __main__ - INFO - Epoch 71, Batch 50, Loss: 13.8303
2026-02-09 20:40:07,305 - __main__ - INFO - Epoch 71, Batch 100, Loss: 11.2304
2026-02-09 20:40:07,534 - __main__ - INFO - Epoch 71, Batch 150, Loss: 12.3852
2026-02-09 20:40:07,741 - __main__ - INFO - Epoch 71, Batch 200, Loss: 13.3707
2026-02-09 20:40:07,945 - __main__ - INFO - Epoch 71, Batch 250, Loss: 12.6533
2026-02-09 20:40:08,147 - __main__ - INFO - Epoch 71, Batch 300, Loss: 14.2678
2026-02-09 20:40:08,497 - __main__ - INFO - Epoch 71: Train Loss: 12.9624, Val Loss: 15.4829
2026-02-09 20:40:08,618 - __main__ - INFO - Epoch 72, Batch 0, Loss: 13.3894
2026-02-09 20:40:08,819 - __main__ - INFO - Epoch 72, Batch 50, Loss: 13.1469
2026-02-09 20:40:09,022 - __main__ - INFO - Epoch 72, Batch 100, Loss: 13.4068
2026-02-09 20:40:09,239 - __main__ - INFO - Epoch 72, Batch 150, Loss: 12.0255
2026-02-09 20:40:09,464 - __main__ - INFO - Epoch 72, Batch 200, Loss: 12.4514
2026-02-09 20:40:09,669 - __main__ - INFO - Epoch 72, Batch 250, Loss: 13.1795
2026-02-09 20:40:09,870 - __main__ - INFO - Epoch 72, Batch 300, Loss: 12.6127
2026-02-09 20:40:10,194 - __main__ - INFO - Epoch 72: Train Loss: 12.9510, Val Loss: 15.4262
2026-02-09 20:40:10,312 - __main__ - INFO - Epoch 73, Batch 0, Loss: 12.5508
2026-02-09 20:40:10,563 - __main__ - INFO - Epoch 73, Batch 50, Loss: 13.1989
2026-02-09 20:40:10,784 - __main__ - INFO - Epoch 73, Batch 100, Loss: 12.6511
2026-02-09 20:40:10,995 - __main__ - INFO - Epoch 73, Batch 150, Loss: 13.8950
2026-02-09 20:40:11,199 - __main__ - INFO - Epoch 73, Batch 200, Loss: 11.0333
2026-02-09 20:40:11,420 - __main__ - INFO - Epoch 73, Batch 250, Loss: 13.5965
2026-02-09 20:40:11,625 - __main__ - INFO - Epoch 73, Batch 300, Loss: 13.1804
2026-02-09 20:40:11,963 - __main__ - INFO - Epoch 73: Train Loss: 12.9458, Val Loss: 15.5676
2026-02-09 20:40:12,081 - __main__ - INFO - Epoch 74, Batch 0, Loss: 12.6332
2026-02-09 20:40:12,303 - __main__ - INFO - Epoch 74, Batch 50, Loss: 13.4356
2026-02-09 20:40:12,533 - __main__ - INFO - Epoch 74, Batch 100, Loss: 12.0625
2026-02-09 20:40:12,747 - __main__ - INFO - Epoch 74, Batch 150, Loss: 13.7392
2026-02-09 20:40:12,953 - __main__ - INFO - Epoch 74, Batch 200, Loss: 12.9651
2026-02-09 20:40:13,156 - __main__ - INFO - Epoch 74, Batch 250, Loss: 10.2863
2026-02-09 20:40:13,398 - __main__ - INFO - Epoch 74, Batch 300, Loss: 14.2087
2026-02-09 20:40:13,748 - __main__ - INFO - Epoch 74: Train Loss: 12.9322, Val Loss: 15.4822
2026-02-09 20:40:13,846 - __main__ - INFO - Epoch 75, Batch 0, Loss: 12.1556
2026-02-09 20:40:14,071 - __main__ - INFO - Epoch 75, Batch 50, Loss: 12.0862
2026-02-09 20:40:14,286 - __main__ - INFO - Epoch 75, Batch 100, Loss: 12.4650
2026-02-09 20:40:14,534 - __main__ - INFO - Epoch 75, Batch 150, Loss: 13.0569
2026-02-09 20:40:14,739 - __main__ - INFO - Epoch 75, Batch 200, Loss: 10.9926
2026-02-09 20:40:14,942 - __main__ - INFO - Epoch 75, Batch 250, Loss: 13.4295
2026-02-09 20:40:15,140 - __main__ - INFO - Epoch 75, Batch 300, Loss: 13.7802
2026-02-09 20:40:15,468 - __main__ - INFO - Epoch 75: Train Loss: 12.9382, Val Loss: 15.6323
2026-02-09 20:40:15,564 - __main__ - INFO - Epoch 76, Batch 0, Loss: 13.1842
2026-02-09 20:40:15,787 - __main__ - INFO - Epoch 76, Batch 50, Loss: 13.1653
2026-02-09 20:40:15,991 - __main__ - INFO - Epoch 76, Batch 100, Loss: 12.8324
2026-02-09 20:40:16,196 - __main__ - INFO - Epoch 76, Batch 150, Loss: 14.2960
2026-02-09 20:40:16,447 - __main__ - INFO - Epoch 76, Batch 200, Loss: 13.7117
2026-02-09 20:40:16,665 - __main__ - INFO - Epoch 76, Batch 250, Loss: 12.2904
2026-02-09 20:40:16,867 - __main__ - INFO - Epoch 76, Batch 300, Loss: 13.3960
2026-02-09 20:40:17,206 - __main__ - INFO - Epoch 76: Train Loss: 12.9865, Val Loss: 15.4343
2026-02-09 20:40:17,336 - __main__ - INFO - Epoch 77, Batch 0, Loss: 12.6050
2026-02-09 20:40:17,540 - __main__ - INFO - Epoch 77, Batch 50, Loss: 12.4765
2026-02-09 20:40:17,749 - __main__ - INFO - Epoch 77, Batch 100, Loss: 14.9630
2026-02-09 20:40:17,973 - __main__ - INFO - Epoch 77, Batch 150, Loss: 12.8693
2026-02-09 20:40:18,167 - __main__ - INFO - Epoch 77, Batch 200, Loss: 14.2123
2026-02-09 20:40:18,412 - __main__ - INFO - Epoch 77, Batch 250, Loss: 13.3275
2026-02-09 20:40:18,623 - __main__ - INFO - Epoch 77, Batch 300, Loss: 13.0763
2026-02-09 20:40:18,948 - __main__ - INFO - Epoch 77: Train Loss: 12.9198, Val Loss: 15.4718
2026-02-09 20:40:19,045 - __main__ - INFO - Epoch 78, Batch 0, Loss: 12.4590
2026-02-09 20:40:19,301 - __main__ - INFO - Epoch 78, Batch 50, Loss: 13.2246
2026-02-09 20:40:19,507 - __main__ - INFO - Epoch 78, Batch 100, Loss: 12.8194
2026-02-09 20:40:19,727 - __main__ - INFO - Epoch 78, Batch 150, Loss: 11.4188
2026-02-09 20:40:19,936 - __main__ - INFO - Epoch 78, Batch 200, Loss: 14.2096
2026-02-09 20:40:20,148 - __main__ - INFO - Epoch 78, Batch 250, Loss: 13.4390
2026-02-09 20:40:20,386 - __main__ - INFO - Epoch 78, Batch 300, Loss: 13.9399
2026-02-09 20:40:20,717 - __main__ - INFO - Epoch 78: Train Loss: 12.9690, Val Loss: 15.6429
2026-02-09 20:40:20,832 - __main__ - INFO - Epoch 79, Batch 0, Loss: 13.3427
2026-02-09 20:40:21,031 - __main__ - INFO - Epoch 79, Batch 50, Loss: 14.2150
2026-02-09 20:40:21,239 - __main__ - INFO - Epoch 79, Batch 100, Loss: 12.5388
2026-02-09 20:40:21,466 - __main__ - INFO - Epoch 79, Batch 150, Loss: 14.1730
2026-02-09 20:40:21,680 - __main__ - INFO - Epoch 79, Batch 200, Loss: 13.0567
2026-02-09 20:40:21,899 - __main__ - INFO - Epoch 79, Batch 250, Loss: 13.1398
2026-02-09 20:40:22,099 - __main__ - INFO - Epoch 79, Batch 300, Loss: 14.0507
2026-02-09 20:40:22,475 - __main__ - INFO - Epoch 79: Train Loss: 12.9424, Val Loss: 15.4868
2026-02-09 20:40:22,584 - __main__ - INFO - Epoch 80, Batch 0, Loss: 11.5037
2026-02-09 20:40:22,813 - __main__ - INFO - Epoch 80, Batch 50, Loss: 12.0658
2026-02-09 20:40:23,013 - __main__ - INFO - Epoch 80, Batch 100, Loss: 12.1894
2026-02-09 20:40:23,223 - __main__ - INFO - Epoch 80, Batch 150, Loss: 10.7651
2026-02-09 20:40:23,439 - __main__ - INFO - Epoch 80, Batch 200, Loss: 11.0908
2026-02-09 20:40:23,653 - __main__ - INFO - Epoch 80, Batch 250, Loss: 14.0484
2026-02-09 20:40:23,862 - __main__ - INFO - Epoch 80, Batch 300, Loss: 13.6980
2026-02-09 20:40:24,209 - __main__ - INFO - Epoch 80: Train Loss: 12.9463, Val Loss: 15.4648
2026-02-09 20:40:24,366 - __main__ - INFO - Epoch 81, Batch 0, Loss: 15.0531
2026-02-09 20:40:24,588 - __main__ - INFO - Epoch 81, Batch 50, Loss: 12.6317
2026-02-09 20:40:24,795 - __main__ - INFO - Epoch 81, Batch 100, Loss: 12.9623
2026-02-09 20:40:25,009 - __main__ - INFO - Epoch 81, Batch 150, Loss: 14.4525
2026-02-09 20:40:25,214 - __main__ - INFO - Epoch 81, Batch 200, Loss: 12.8793
2026-02-09 20:40:25,434 - __main__ - INFO - Epoch 81, Batch 250, Loss: 13.1223
2026-02-09 20:40:25,640 - __main__ - INFO - Epoch 81, Batch 300, Loss: 11.9760
2026-02-09 20:40:25,988 - __main__ - INFO - Epoch 81: Train Loss: 12.9474, Val Loss: 15.5184
2026-02-09 20:40:26,104 - __main__ - INFO - Epoch 82, Batch 0, Loss: 12.8676
2026-02-09 20:40:26,330 - __main__ - INFO - Epoch 82, Batch 50, Loss: 12.0286
2026-02-09 20:40:26,554 - __main__ - INFO - Epoch 82, Batch 100, Loss: 13.7788
2026-02-09 20:40:26,766 - __main__ - INFO - Epoch 82, Batch 150, Loss: 11.6911
2026-02-09 20:40:26,972 - __main__ - INFO - Epoch 82, Batch 200, Loss: 12.7097
2026-02-09 20:40:27,182 - __main__ - INFO - Epoch 82, Batch 250, Loss: 11.6545
2026-02-09 20:40:27,408 - __main__ - INFO - Epoch 82, Batch 300, Loss: 12.4017
2026-02-09 20:40:27,739 - __main__ - INFO - Epoch 82: Train Loss: 12.9388, Val Loss: 15.4709
2026-02-09 20:40:27,859 - __main__ - INFO - Epoch 83, Batch 0, Loss: 14.3331
2026-02-09 20:40:28,065 - __main__ - INFO - Epoch 83, Batch 50, Loss: 11.2724
2026-02-09 20:40:28,267 - __main__ - INFO - Epoch 83, Batch 100, Loss: 14.0722
2026-02-09 20:40:28,519 - __main__ - INFO - Epoch 83, Batch 150, Loss: 10.7139
2026-02-09 20:40:28,735 - __main__ - INFO - Epoch 83, Batch 200, Loss: 12.2448
2026-02-09 20:40:28,934 - __main__ - INFO - Epoch 83, Batch 250, Loss: 11.5157
2026-02-09 20:40:29,132 - __main__ - INFO - Epoch 83, Batch 300, Loss: 13.7787
2026-02-09 20:40:29,491 - __main__ - INFO - Epoch 83: Train Loss: 12.9320, Val Loss: 15.5270
2026-02-09 20:40:29,612 - __main__ - INFO - Epoch 84, Batch 0, Loss: 14.3868
2026-02-09 20:40:29,822 - __main__ - INFO - Epoch 84, Batch 50, Loss: 14.4824
2026-02-09 20:40:30,028 - __main__ - INFO - Epoch 84, Batch 100, Loss: 12.5426
2026-02-09 20:40:30,239 - __main__ - INFO - Epoch 84, Batch 150, Loss: 11.7909
2026-02-09 20:40:30,483 - __main__ - INFO - Epoch 84, Batch 200, Loss: 12.6473
2026-02-09 20:40:30,686 - __main__ - INFO - Epoch 84, Batch 250, Loss: 12.4246
2026-02-09 20:40:30,886 - __main__ - INFO - Epoch 84, Batch 300, Loss: 11.6610
2026-02-09 20:40:31,209 - __main__ - INFO - Epoch 84: Train Loss: 12.9388, Val Loss: 15.5553
2026-02-09 20:40:31,337 - __main__ - INFO - Epoch 85, Batch 0, Loss: 12.9203
2026-02-09 20:40:31,544 - __main__ - INFO - Epoch 85, Batch 50, Loss: 12.3610
2026-02-09 20:40:31,755 - __main__ - INFO - Epoch 85, Batch 100, Loss: 14.5037
2026-02-09 20:40:31,968 - __main__ - INFO - Epoch 85, Batch 150, Loss: 12.5151
2026-02-09 20:40:32,169 - __main__ - INFO - Epoch 85, Batch 200, Loss: 12.9856
2026-02-09 20:40:32,410 - __main__ - INFO - Epoch 85, Batch 250, Loss: 11.6420
2026-02-09 20:40:32,622 - __main__ - INFO - Epoch 85, Batch 300, Loss: 13.0309
2026-02-09 20:40:32,960 - __main__ - INFO - Epoch 85: Train Loss: 12.9411, Val Loss: 15.4567
2026-02-09 20:40:33,080 - __main__ - INFO - Epoch 86, Batch 0, Loss: 13.2723
2026-02-09 20:40:33,311 - __main__ - INFO - Epoch 86, Batch 50, Loss: 12.5995
2026-02-09 20:40:33,526 - __main__ - INFO - Epoch 86, Batch 100, Loss: 13.5360
2026-02-09 20:40:33,739 - __main__ - INFO - Epoch 86, Batch 150, Loss: 11.0229
2026-02-09 20:40:33,945 - __main__ - INFO - Epoch 86, Batch 200, Loss: 12.7440
2026-02-09 20:40:34,154 - __main__ - INFO - Epoch 86, Batch 250, Loss: 12.8636
2026-02-09 20:40:34,392 - __main__ - INFO - Epoch 86, Batch 300, Loss: 12.5427
2026-02-09 20:40:34,722 - __main__ - INFO - Epoch 86: Train Loss: 12.9331, Val Loss: 15.4196
2026-02-09 20:40:34,837 - __main__ - INFO - Epoch 87, Batch 0, Loss: 13.2368
2026-02-09 20:40:35,064 - __main__ - INFO - Epoch 87, Batch 50, Loss: 12.5994
2026-02-09 20:40:35,267 - __main__ - INFO - Epoch 87, Batch 100, Loss: 12.6731
2026-02-09 20:40:35,498 - __main__ - INFO - Epoch 87, Batch 150, Loss: 12.4764
2026-02-09 20:40:35,702 - __main__ - INFO - Epoch 87, Batch 200, Loss: 12.9672
2026-02-09 20:40:35,920 - __main__ - INFO - Epoch 87, Batch 250, Loss: 11.9529
2026-02-09 20:40:36,123 - __main__ - INFO - Epoch 87, Batch 300, Loss: 13.1659
2026-02-09 20:40:36,503 - __main__ - INFO - Epoch 87: Train Loss: 12.9334, Val Loss: 15.4455
2026-02-09 20:40:36,599 - __main__ - INFO - Epoch 88, Batch 0, Loss: 12.4773
2026-02-09 20:40:36,833 - __main__ - INFO - Epoch 88, Batch 50, Loss: 14.3629
2026-02-09 20:40:37,046 - __main__ - INFO - Epoch 88, Batch 100, Loss: 13.3376
2026-02-09 20:40:37,256 - __main__ - INFO - Epoch 88, Batch 150, Loss: 12.4481
2026-02-09 20:40:37,480 - __main__ - INFO - Epoch 88, Batch 200, Loss: 14.7685
2026-02-09 20:40:37,682 - __main__ - INFO - Epoch 88, Batch 250, Loss: 13.3438
2026-02-09 20:40:37,883 - __main__ - INFO - Epoch 88, Batch 300, Loss: 14.5840
2026-02-09 20:40:38,208 - __main__ - INFO - Epoch 88: Train Loss: 12.9297, Val Loss: 15.4111
2026-02-09 20:40:38,375 - __main__ - INFO - Epoch 89, Batch 0, Loss: 13.3524
2026-02-09 20:40:38,591 - __main__ - INFO - Epoch 89, Batch 50, Loss: 12.6121
2026-02-09 20:40:38,794 - __main__ - INFO - Epoch 89, Batch 100, Loss: 12.4952
2026-02-09 20:40:39,009 - __main__ - INFO - Epoch 89, Batch 150, Loss: 11.9315
2026-02-09 20:40:39,212 - __main__ - INFO - Epoch 89, Batch 200, Loss: 12.9230
2026-02-09 20:40:39,429 - __main__ - INFO - Epoch 89, Batch 250, Loss: 13.1187
2026-02-09 20:40:39,630 - __main__ - INFO - Epoch 89, Batch 300, Loss: 12.2443
2026-02-09 20:40:39,953 - __main__ - INFO - Epoch 89: Train Loss: 12.9406, Val Loss: 15.3757
2026-02-09 20:40:40,067 - __main__ - INFO - Epoch 90, Batch 0, Loss: 13.2585
2026-02-09 20:40:40,257 - __main__ - INFO - Epoch 90, Batch 50, Loss: 12.0891
2026-02-09 20:40:40,502 - __main__ - INFO - Epoch 90, Batch 100, Loss: 12.6579
2026-02-09 20:40:40,730 - __main__ - INFO - Epoch 90, Batch 150, Loss: 11.1596
2026-02-09 20:40:40,928 - __main__ - INFO - Epoch 90, Batch 200, Loss: 12.5339
2026-02-09 20:40:41,137 - __main__ - INFO - Epoch 90, Batch 250, Loss: 11.6082
2026-02-09 20:40:41,349 - __main__ - INFO - Epoch 90, Batch 300, Loss: 14.9154
2026-02-09 20:40:41,672 - __main__ - INFO - Epoch 90: Train Loss: 12.9284, Val Loss: 15.3897
2026-02-09 20:40:41,791 - __main__ - INFO - Epoch 91, Batch 0, Loss: 12.2492
2026-02-09 20:40:42,018 - __main__ - INFO - Epoch 91, Batch 50, Loss: 13.3014
2026-02-09 20:40:42,219 - __main__ - INFO - Epoch 91, Batch 100, Loss: 12.7683
2026-02-09 20:40:42,466 - __main__ - INFO - Epoch 91, Batch 150, Loss: 13.5457
2026-02-09 20:40:42,682 - __main__ - INFO - Epoch 91, Batch 200, Loss: 10.5623
2026-02-09 20:40:42,884 - __main__ - INFO - Epoch 91, Batch 250, Loss: 15.1363
2026-02-09 20:40:43,086 - __main__ - INFO - Epoch 91, Batch 300, Loss: 12.3515
2026-02-09 20:40:43,420 - __main__ - INFO - Epoch 91: Train Loss: 12.9400, Val Loss: 15.4300
2026-02-09 20:40:43,515 - __main__ - INFO - Epoch 92, Batch 0, Loss: 10.4886
2026-02-09 20:40:43,746 - __main__ - INFO - Epoch 92, Batch 50, Loss: 11.2089
2026-02-09 20:40:43,949 - __main__ - INFO - Epoch 92, Batch 100, Loss: 15.3885
2026-02-09 20:40:44,158 - __main__ - INFO - Epoch 92, Batch 150, Loss: 11.6714
2026-02-09 20:40:44,394 - __main__ - INFO - Epoch 92, Batch 200, Loss: 13.5650
2026-02-09 20:40:44,598 - __main__ - INFO - Epoch 92, Batch 250, Loss: 12.3074
2026-02-09 20:40:44,811 - __main__ - INFO - Epoch 92, Batch 300, Loss: 11.1280
2026-02-09 20:40:45,146 - __main__ - INFO - Epoch 92: Train Loss: 12.9251, Val Loss: 15.4039
2026-02-09 20:40:45,268 - __main__ - INFO - Epoch 93, Batch 0, Loss: 14.0082
2026-02-09 20:40:45,491 - __main__ - INFO - Epoch 93, Batch 50, Loss: 11.7576
2026-02-09 20:40:45,698 - __main__ - INFO - Epoch 93, Batch 100, Loss: 13.4341
2026-02-09 20:40:45,913 - __main__ - INFO - Epoch 93, Batch 150, Loss: 12.3170
2026-02-09 20:40:46,113 - __main__ - INFO - Epoch 93, Batch 200, Loss: 11.6391
2026-02-09 20:40:46,331 - __main__ - INFO - Epoch 93, Batch 250, Loss: 11.7827
2026-02-09 20:40:46,562 - __main__ - INFO - Epoch 93, Batch 300, Loss: 12.7459
2026-02-09 20:40:46,898 - __main__ - INFO - Epoch 93: Train Loss: 12.9318, Val Loss: 15.4002
2026-02-09 20:40:47,016 - __main__ - INFO - Epoch 94, Batch 0, Loss: 11.3147
2026-02-09 20:40:47,213 - __main__ - INFO - Epoch 94, Batch 50, Loss: 12.8432
2026-02-09 20:40:47,434 - __main__ - INFO - Epoch 94, Batch 100, Loss: 11.5854
2026-02-09 20:40:47,661 - __main__ - INFO - Epoch 94, Batch 150, Loss: 13.7006
2026-02-09 20:40:47,876 - __main__ - INFO - Epoch 94, Batch 200, Loss: 14.3545
2026-02-09 20:40:48,081 - __main__ - INFO - Epoch 94, Batch 250, Loss: 12.5020
2026-02-09 20:40:48,282 - __main__ - INFO - Epoch 94, Batch 300, Loss: 11.7673
2026-02-09 20:40:48,630 - __main__ - INFO - Epoch 94: Train Loss: 12.9474, Val Loss: 15.3898
2026-02-09 20:40:48,745 - __main__ - INFO - Epoch 95, Batch 0, Loss: 11.7465
2026-02-09 20:40:48,966 - __main__ - INFO - Epoch 95, Batch 50, Loss: 11.7955
2026-02-09 20:40:49,171 - __main__ - INFO - Epoch 95, Batch 100, Loss: 12.9817
2026-02-09 20:40:49,393 - __main__ - INFO - Epoch 95, Batch 150, Loss: 12.2502
2026-02-09 20:40:49,590 - __main__ - INFO - Epoch 95, Batch 200, Loss: 12.9734
2026-02-09 20:40:49,796 - __main__ - INFO - Epoch 95, Batch 250, Loss: 12.8613
2026-02-09 20:40:50,005 - __main__ - INFO - Epoch 95, Batch 300, Loss: 14.6244
2026-02-09 20:40:50,384 - __main__ - INFO - Epoch 95: Train Loss: 12.9406, Val Loss: 15.3858
2026-02-09 20:40:50,502 - __main__ - INFO - Epoch 96, Batch 0, Loss: 13.1005
2026-02-09 20:40:50,703 - __main__ - INFO - Epoch 96, Batch 50, Loss: 13.3484
2026-02-09 20:40:50,905 - __main__ - INFO - Epoch 96, Batch 100, Loss: 11.0352
2026-02-09 20:40:51,121 - __main__ - INFO - Epoch 96, Batch 150, Loss: 13.7053
2026-02-09 20:40:51,343 - __main__ - INFO - Epoch 96, Batch 200, Loss: 13.7681
2026-02-09 20:40:51,561 - __main__ - INFO - Epoch 96, Batch 250, Loss: 13.2809
2026-02-09 20:40:51,781 - __main__ - INFO - Epoch 96, Batch 300, Loss: 12.2760
2026-02-09 20:40:52,113 - __main__ - INFO - Epoch 96: Train Loss: 12.9447, Val Loss: 15.3995
2026-02-09 20:40:52,232 - __main__ - INFO - Epoch 97, Batch 0, Loss: 12.5598
2026-02-09 20:40:52,496 - __main__ - INFO - Epoch 97, Batch 50, Loss: 12.8003
2026-02-09 20:40:52,703 - __main__ - INFO - Epoch 97, Batch 100, Loss: 12.3847
2026-02-09 20:40:52,915 - __main__ - INFO - Epoch 97, Batch 150, Loss: 14.6691
2026-02-09 20:40:53,124 - __main__ - INFO - Epoch 97, Batch 200, Loss: 12.8973
2026-02-09 20:40:53,346 - __main__ - INFO - Epoch 97, Batch 250, Loss: 13.2977
2026-02-09 20:40:53,568 - __main__ - INFO - Epoch 97, Batch 300, Loss: 12.1378
2026-02-09 20:40:53,906 - __main__ - INFO - Epoch 97: Train Loss: 12.9444, Val Loss: 15.3915
2026-02-09 20:40:54,037 - __main__ - INFO - Epoch 98, Batch 0, Loss: 12.7201
2026-02-09 20:40:54,248 - __main__ - INFO - Epoch 98, Batch 50, Loss: 14.3865
2026-02-09 20:40:54,496 - __main__ - INFO - Epoch 98, Batch 100, Loss: 12.8470
2026-02-09 20:40:54,713 - __main__ - INFO - Epoch 98, Batch 150, Loss: 11.3777
2026-02-09 20:40:54,919 - __main__ - INFO - Epoch 98, Batch 200, Loss: 12.8655
2026-02-09 20:40:55,124 - __main__ - INFO - Epoch 98, Batch 250, Loss: 13.3246
2026-02-09 20:40:55,338 - __main__ - INFO - Epoch 98, Batch 300, Loss: 13.2171
2026-02-09 20:40:55,668 - __main__ - INFO - Epoch 98: Train Loss: 12.9340, Val Loss: 15.3924
2026-02-09 20:40:55,763 - __main__ - INFO - Epoch 99, Batch 0, Loss: 11.4804
2026-02-09 20:40:55,995 - __main__ - INFO - Epoch 99, Batch 50, Loss: 12.5307
2026-02-09 20:40:56,203 - __main__ - INFO - Epoch 99, Batch 100, Loss: 13.6120
2026-02-09 20:40:56,467 - __main__ - INFO - Epoch 99, Batch 150, Loss: 13.9219
2026-02-09 20:40:56,700 - __main__ - INFO - Epoch 99, Batch 200, Loss: 14.3657
2026-02-09 20:40:56,904 - __main__ - INFO - Epoch 99, Batch 250, Loss: 11.6965
2026-02-09 20:40:57,110 - __main__ - INFO - Epoch 99, Batch 300, Loss: 12.3855
2026-02-09 20:40:57,446 - __main__ - INFO - Epoch 99: Train Loss: 12.9349, Val Loss: 15.3907
2026-02-09 20:40:57,567 - __main__ - INFO - Epoch 100, Batch 0, Loss: 13.1282
2026-02-09 20:40:57,791 - __main__ - INFO - Epoch 100, Batch 50, Loss: 11.4709
2026-02-09 20:40:58,000 - __main__ - INFO - Epoch 100, Batch 100, Loss: 12.7880
2026-02-09 20:40:58,216 - __main__ - INFO - Epoch 100, Batch 150, Loss: 11.6697
2026-02-09 20:40:58,459 - __main__ - INFO - Epoch 100, Batch 200, Loss: 12.9412
2026-02-09 20:40:58,667 - __main__ - INFO - Epoch 100, Batch 250, Loss: 13.7678
2026-02-09 20:40:58,880 - __main__ - INFO - Epoch 100, Batch 300, Loss: 13.1864
2026-02-09 20:40:59,200 - __main__ - INFO - Epoch 100: Train Loss: 12.9133, Val Loss: 15.3904
2026-02-09 20:40:59,200 - __main__ - INFO - Training completed!
2026-02-09 20:40:59,211 - __main__ - INFO - Model saved to checkpoints/trained_model.pt
2026-02-09 20:40:59,212 - __main__ - INFO - Evaluating on test set...
2026-02-09 20:40:59,343 - __main__ - INFO - Test Loss: 0.0000
2026-02-09 20:40:59,343 - __main__ - INFO - Training metrics saved to results/training_metrics.json
2026-02-09 20:40:59,343 - __main__ - INFO - Training completed successfully!
